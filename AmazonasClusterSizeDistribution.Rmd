---
title: "Amazon Compute Cluster Size Distribution"
output: html_notebook
editor_options: 
  chunk_output_type: console
---

## setup

* Using Amazonas shape from http://worldmap.harvard.edu/data/geonode:amapoly_ivb

* Update files in server

rsync -azP --exclude "*.zip" -e 'ssh -p 33100' /home/leonardo/Academicos/GitProjects/AmazonTippingPoint/ leonardo@127.0.0.1:~/GitProjects/AmazonTippingPoint

```{r setup, echo=FALSE,message=FALSE,warning=FALSE,fig.align='center',eval=TRUE}
source("R/functions.r")
require(raster)
require(dplyr)
require(stringr)
require(spatialwarnings)
require(future.apply)
require(tictoc)
require(readr)

# Data Path
#
if( Sys.info()['nodename'] =="ls-pro") {
  
  data_path <- "~/Academicos/GitProjects/AmazonTippingPoint/Data"
} else if(Sys.info()['nodename'] =="biologia2018") {                     # Server UNGS
  data_path <- "~/GitProjects/AmazonTippingPoint/Data"
} else if(Sys.info()['nodename'] =="MacLeonardo.local") {                     # Mac Pro
  data_path <- "/Users/leonardosaravia/Academicos/GitProjects/AmazonTippingPoint/Data"  
}


file_pattern <- "^BurnedAreaAmazon20"
fire_bricks <- list.files(path=data_path,pattern=file_pattern)
fire_bricks
region_name  <- str_match(fire_bricks, "^BurnedArea(.*?)20\\d{2}")[1,2]

```

## Get the data in sparse format

* The file Data/patch_df_BurnedArea_Amazon.rds has the distribution fitted by month

```{r readFilesAustralia, echo=FALSE,message=FALSE,warning=FALSE,fig.align='center',eval=FALSE}


fname <- paste0("Data/patch_sparse_BurnedArea_", region_name, ".rds" )
if(file.exists(fname)) {
  patch_sparse <- readRDS(fname)
} else {
  patch_sparse <- tibble()
}


tic()
plan(multisession)

patch_add <- convert_to_sparse_days(fire_bricks,region_name,data_path)

plan(sequential)
toc()

str(patch_add)
patch_sparse <- bind_rows(patch_sparse, patch_add)

saveRDS(patch_sparse,fname)

rm(patch_add)
```


# Read Files and fit patch distribution by month

```{r FitByMonthAmazon, echo=FALSE,message=FALSE,warning=FALSE,fig.align='center',eval=FALSE}
source("R/functions.r")
require(raster)
require(dplyr)
require(stringr)
require(spatialwarnings)
require(future.apply)
require(tictoc)
require(readr)


patch_df_name <- paste0("Data/patch_df_BurnedArea_",region_name, ".rds")

# Read the data.frame with fitted EWS data
#
if(file.exists(patch_df_name)) {
  patch_df <- readRDS(patch_df_name)
} else {
  patch_df <- tibble()
}

# Main lapply for fitting distributions of patch size 
#
tic()
plan(multisession)
p_df <- lapply( seq_along(fire_bricks), function(i){
  br <- brick(paste0(data_path,"/",fire_bricks[i]))
  df <- future_lapply(seq_len(nbands(br)), function(x){evaluate_patch_distr(br[[x]]) })
  df <- bind_rows(df) %>% mutate(region= region_name)  %>% select(region, date, everything())
})
patch_df <- bind_rows(patch_df,do.call(rbind,p_df))
toc()

saveRDS(patch_df,patch_df_name)
```

# Save Patch distribution

```{r SavePatchByMonthAmazonNew, echo=FALSE,message=FALSE,warning=FALSE,fig.align='center',eval=FALSE}

#
# Save patch distribution
#
patch_size_name <- paste0("Data/patch_size_BurnedArea_",region_name, ".rds")

if(file.exists(patch_size_name)) {
  patch_size <- readRDS(patch_size_name)
} else {
  patch_size <- tibble()
}

tic()
plan(multisession)
p_df <- lapply( seq_along(fire_bricks), function(i){
  br <- brick(paste0(data_path,"/",fire_bricks[i]))
  df <- future_lapply(seq_len(nbands(br)), function(x){evaluate_patch_distr(br[[x]], FALSE) }) # future_
  df <- bind_rows(df) %>% mutate(region= region_name)  %>% dplyr::select(region, date, everything())

})
plan(sequential)

patch_size <- bind_rows(patch_size,do.call(rbind,p_df))
toc()

saveRDS(patch_size,patch_size_name)
```


# Plot Monthly Patch distribution

```{r PlotPatchByMonthAmazon, echo=FALSE,message=FALSE,warning=FALSE,fig.align='center',eval=FALSE}

patch_size_name <- paste0("Data/patch_size_BurnedArea_",region_name, ".rds")

if(file.exists(patch_size_name)) {
  patch_size <- readRDS(patch_size_name) %>% mutate(date=ymd(date))%>% filter(date>="2001-01-01" & date<"2022-01-01" )
} else {
  stop(paste("No patch size file: ", patch_size_name))
}

#
# Calculate total forest region area in pixels 
#
fire_bricks <- list.files(path=data_path,pattern="^BurnedAreaAmazon_.*tif$")
fire_bricks
patch_sparse <- convert_to_sparse(fire_bricks,region_name,data_path)
total_forest <- nrow(patch_sparse)

#
# Total Area in pixels 31364191
#
total_forest <- 31364191

#
# Patch Plots 
#
require(ggrepel)
require(lubridate)
require(plotly)
p1 <- patch_size %>% group_by(date) %>% 
  summarize(no_patch=n()/total_forest*100,tot_patch=sum(size)/total_forest*100) %>% 
  mutate( label =as.character(date)) %>%
  filter( month(date) %in% c(4,5,6,7,8,9,10)) %>% 
  ggplot(  aes(no_patch,tot_patch, label=label,color=year(date) ))+ geom_point() + theme_bw() +
      scale_color_viridis_c(guide=FALSE)  + 
      xlab("Number of Patches") +  
      ylab("Total Size (%)") +  
      theme(axis.text.x = element_text(angle = 90, hjust = 1))   #+ scale_x_log10() + scale_y_log10()
ggplotly(p1)

patch_size %>% mutate(date=ymd(date)) %>% group_by(date) %>% 
  summarize(no_patch=n()/total_forest*100,tot_patch=sum(size)/total_forest*100) %>% 
   filter( month(date) %in% c(4,5,6,7,8,9,10)) %>% 
  mutate( label =ifelse(date =="2010-08-01" | date=="2005-08-01" | date=="2020-08-01" | date=="2010-09-01" | date=="2007-09-01" | date=="2004-09-01",as.character(date),"")) %>%
  ggplot(  aes(no_patch,tot_patch, label=label,color=year(date) ))+ geom_point() + theme_bw() +
      scale_color_viridis_c(guide=FALSE)  + 
      xlab("Number of Patches") +  
      ylab("Total Size (%)") +  
      theme(axis.text.x = element_text(angle = 90, hjust = 1)) + geom_text_repel()

ggsave("figure/Amazon_NumberVsSize_Month.jpg",width=8,height=6,units="in",dpi=600)



p1 <- patch_size %>% mutate(date=ymd(date)) %>% group_by(date) %>% 
  summarize(no_patch=n()/total_forest*100,tot_patch=max(size)/total_forest*100) %>% 
  mutate( label =as.character(date)) %>%
  filter( month(date) %in% c(4,5,6,7,8,9,10)) %>%
  ggplot(  aes(no_patch,tot_patch, label=label,color=year(date) ))+ geom_point() + theme_bw() +
      scale_color_viridis_c(guide=FALSE)  + 
      xlab("Number of Patches") +  
      ylab("Max Size (%)") +  
      theme(axis.text.x = element_text(angle = 50, hjust = 1))   + geom_text_repel()
ggplotly(p1)

p1 <- patch_size %>% mutate(date=ymd(date)) %>% group_by(date) %>% 
  summarize(no_patch=n()/total_forest*100,tot_patch=max(size)/total_forest*100) %>% 
  mutate( label =as.character(date)) %>%
  filter( month(date) %in% c(4,5,6,7,8,9,10)) %>%
  mutate( label =ifelse(date =="2010-08-01" | date=="2007-09-01" | date=="2010-09-01" | date=="2005-09-01" | date=="2004-09-01",as.character(date),"")) %>%
  ggplot(  aes(no_patch,tot_patch, label=label,color=year(date) ))+ geom_point() + theme_bw() +
      scale_color_viridis_c(guide=FALSE)  + 
      xlab("Number of Patches") +  
      ylab("Max Size (%)") +  
      theme(axis.text.x = element_text(angle = 50, hjust = 1))   + geom_text_repel()
ggsave("figure/Amazon_MaxSizeVsNumber_Month.jpg",plot=p1,width=8,height=6,units="in",dpi=600)


p1 <- patch_size %>% group_by(date) %>% 
  summarize(max_patch=max(size)/total_forest*100) %>%  
  ggplot(  aes(date,max_patch ))+ geom_line() + theme_bw() +
      scale_color_viridis_c()  + 
      ylab("Max Patch Size %") +  xlab("") + 
      theme(axis.text.x = element_text(angle = 50, hjust = 1)) +  scale_x_date(date_breaks = "1 year")
ggplotly(p1)
ggsave("figure/Amazon_MaxSize_Month.jpg",plot=p1,width=8,height=6,units="in",dpi=600)


p1 <- patch_size %>% mutate(date=ymd(date)) %>% group_by(date) %>% 
  summarize(max_patch=n()/total_forest*100) %>%  
  ggplot(  aes(date,max_patch ))+ geom_line() + theme_bw() +
      scale_color_viridis_c()  + 
      ylab("Number of Patches %") +  
      theme(axis.text.x = element_text(angle = 50, hjust = 1)) +  scale_x_date(date_breaks = "1 year")
ggplotly(p1)
ggsave("figure/Amazon_NumberPatches_Month.jpg",plot=p1,width=8,height=6,units="in",dpi=600)


p1 <- patch_size %>% mutate(date=ymd(date)) %>% group_by(date) %>% 
  summarize(sum_patch=sum(size)/total_forest*100,max_patch=max(size)/total_forest*100) %>%  
  ggplot(  aes(date,sum_patch ))+ geom_line() + theme_bw() +
      scale_color_viridis_c()  + 
      ylab("Total Fire Size %") +  
      theme(axis.text.x = element_text(angle = 50, hjust = 1)) +  scale_x_date(date_breaks = "1 year")
ggplotly(p1)
ggsave("figure/Amazon_TotSize_Month.jpg",plot=p1,width=8,height=6,units="in",dpi=600)


p1 <- patch_size %>% mutate(date=year(date)) %>% group_by(date) %>% 
  summarize(max_patch=max(size)/total_forest*100,tot_patch=sum(size)/total_forest*100) %>% 
  mutate( label =as.character(date)) %>%
   ggplot(  aes(max_patch,tot_patch, label=label,color=date ))+ geom_point() + theme_bw() +
      scale_color_viridis_c(guide=NULL)  + 
      xlab("Maximum fire size (%)") +  
      ylab("Total Size (%)") +  
      theme(axis.text.x = element_text(angle = 50, hjust = 1)) + geom_text_repel()
ggplotly(p1)
ggsave("figure/Amazon_TotSizeVsMaxSize.jpg",plot=p1,width=8,height=6,units="in",dpi=600)

p1 <- patch_size %>% mutate(date=year(date)) %>% group_by(date) %>% 
  summarize(no_patch=n()/total_forest*100,tot_patch=sum(size)/total_forest*100) %>% 
  mutate( label =as.character(date)) %>%
   ggplot(  aes(no_patch,tot_patch, label=label,color=date ))+ geom_point() + theme_bw() +
      scale_color_viridis_c()  + 
      xlab("Number of Patches") +  
      ylab("Total Size (%)") +  
      theme(axis.text.x = element_text(angle = 90, hjust = 1)) + geom_text_repel()
ggplotly(p1)
ggsave("figure/Amazon_TotSizeVsNo_year.jpg",plot=p1,width=8,height=6,units="in",dpi=600)


p1 <- patch_size %>% mutate(date=year(date)) %>% group_by(date) %>% 
  summarize(no_patch=n()/total_forest*100,tot_patch=max(size)/total_forest*100) %>% 
  mutate( label =as.character(date)) %>%
   ggplot(  aes(tot_patch,no_patch, label=label,color=date ))+ geom_point() + theme_bw() +
      scale_color_viridis_c()  + 
      ylab("Number of Patches") +  
      xlab("Max Size (%)") +  
      theme(axis.text.x = element_text(angle = 90, hjust = 1)) + geom_text_repel()
ggplotly(p1)
ggsave("figure/Amazon_MaxSizeVsNo_year.jpg",plot=p1,width=8,height=6,units="in",dpi=600)

```

## Fit Power Laws Centered on the month of max fire 

* For Amazon/Dry Chaco  the months of max fire are 08 09 10

```{r AmazonSeasonalPatchDistrNew, echo=FALSE,message=FALSE,warning=FALSE,fig.align='center',eval=TRUE}
require(lubridate)
require(Matrix)
require(ggplot2)

file_pattern <- "^BurnedAreaAmazon20"
fire_bricks <- list.files(path=data_path,pattern=file_pattern)
fire_bricks
region_name  <- str_match(fire_bricks, "^BurnedArea(.*?)20\\d{2}")[1,2]
fname <- paste0("Data/patch_sparse_BurnedArea_", region_name, ".rds" )
#
# Total Area in pixels 31364191
#
total_forest <- 31364191

if(file.exists(fname)) {
  patch_sparse <- readRDS(fname)
} else {
  stop("Patch sparse file don't exist")
}

# Calculate period from month 01 - 12 07 because the peak is always 07-08-09 
#
if( !("period" %in% names(patch_sparse))) {
  patch_sparse <- patch_sparse %>% mutate(period = year(date) -2000)
  saveRDS(patch_sparse,fname)
}
str(patch_sparse)

## Check if period is well defined 
i <- 0

patch_sparse %>% filter(date=="2000-12-01") 
patch_sparse %>% filter(date=="2001-01-01") 
patch_sparse %>% filter(date=="2019-06-01") 
patch_sparse %>% filter(date=="2019-07-01") 
patch_sparse %>% filter(date=="2020-06-01") 
patch_sparse %>% filter(date=="2021-01-01") 
 

#
# Calculate distribution parameters and store in a data.frame and generic sews
#
patch_dfp_fname <- paste0("Data/patch_dfp_BurnedArea_", region_name, ".rds" )

if(file.exists(patch_dfp_fname)) {
  patch_dfp <- readRDS(patch_dfp_fname)
} else {
  
  patch_dfp <- tibble()
}

# patch_dfp <- patch_dfp %>% tidyr::fill(ln_p_value,exp_p_value)

plan(multisession)
p_df <- future_lapply( unique(patch_sparse$period), function(i){
  br <- patch_sparse[patch_sparse$period == i,]
  spm <- sparseMatrix(br$i,br$j) 
  df <- evaluate_patch_distr(spm,TRUE) %>% mutate(period=i,region= region_name)  %>% dplyr::select(region, date,period, everything())
  #g1 <- generic_sews(as.matrix(spm),subsize = 2) 
  #df <- bind_cols(df, data.frame(t(g1$value)))
})
patch_dfp <- bind_rows(patch_dfp,p_df)

patch_dfp <- patch_dfp %>% mutate(date=2000+period )
patch_dfp <- patch_dfp %>%  arrange(date, range) %>% group_by( date) %>% mutate( range=first(range)) 
saveRDS(patch_dfp,patch_dfp_fname)



#
# Save patch distribution by period
#
patch_size_pfname <- paste0("Data/patch_sizes_p_BurnedArea_", region_name, ".rds" )
if(file.exists(patch_size_pfname)) {
  patch_sizes_p <- readRDS(patch_size_pfname)
} else {
  
  patch_sizes_p <- tibble()
}

# p_df <- future_lapply( 21, function(i){
p_df <- future_lapply( unique(patch_sparse$period), function(i){
  br <- patch_sparse[patch_sparse$period == i,]
  spm <- sparseMatrix(br$i,br$j)
  df <- evaluate_patch_distr(spm,FALSE) %>% mutate(period=i,region= region_name)  %>% dplyr::select(region, date,period, everything())
})
patch_sizes_p <- bind_rows(patch_sizes_p,p_df) 
patch_sizes_p <- patch_sizes_p %>% mutate(date = 2000+ period)

saveRDS(patch_sizes_p,patch_size_pfname)

```

## Plots and tables of fitted distributions  Centered on the month of max fire - Annual

* For Amazon/Dry Chaco  the months of max fire are 08 09 10

```{r PlotsAmazonSeasonalPatchDistr, echo=FALSE,message=FALSE,warning=FALSE,fig.align='center',eval=FALSE}

# Load data
#
patch_size_pfname <- paste0("Data/patch_sizes_p_BurnedArea_", region_name, ".rds" )
if(file.exists(patch_size_pfname)) {
  patch_sizes_p <- readRDS(patch_size_pfname)
}
patch_dfp_fname <- paste0("Data/patch_dfp_BurnedArea_", region_name, ".rds" )

if(file.exists(patch_dfp_fname)) {
  patch_dfp <- readRDS(patch_dfp_fname)
}

#
# Frequency of distributions with min AICc
#
best_patch_dfp <- patch_dfp %>% group_by(date) %>% filter(AICc==min(AICc)) 
knitr::kable(best_patch_dfp %>% group_by(type) %>% summarise(n = n(),expo=median(expo),rate=median(rate)) %>%  mutate(freq = n / sum(n)), digits = 5)


#
# Which years have power law distribution - Criteria min AICc and different from exponential
#
knitr::kable(patch_dfp %>% group_by(date) %>% filter(AICc == min(AICc)) %>% dplyr::select(date,type:range,exp_p_value,ln_p_value))

patch_dfp %>% group_by(date) %>% filter(AICc == min(AICc),type=="pl") %>% ungroup() %>% summarize(range(expo),median(expo)) 

#
# Plot power law fittings!
#
plots_fname <- paste0("Data/Plots_p_BurnedArea_", region_name, ".rds" )
if(file.exists(plots_fname)) {
  p_df <- readRDS(plots_fname)
} else {

  p_df <- future_lapply( unique(patch_sparse$period), function(i){
    br <- patch_sparse[patch_sparse$period == i,]
    spm <- sparseMatrix(br$i,br$j) 
    df <- evaluate_patch_distr(spm,returnOBJ = TRUE)
  })
  saveRDS(p_df,plots_fname)
}
plan(sequential)


require(cowplot)
require(scales)
gp <- lapply(seq_len(length(p_df)), function(x){
  
  gg <- p_df[[x]] + ggtitle(1999+x) 
})
gp[[22]]
prow <- plot_grid(
  gp[[4]] + theme(legend.position="none") + scale_x_log10( labels = trans_format("log10", math_format(10^.x))), 
  gp[[5]] + theme(legend.position="none") + scale_x_log10( labels = trans_format("log10", math_format(10^.x))),
  gp[[6]] + theme(legend.position="none") + scale_x_log10(breaks = 10^(0:5), labels = trans_format("log10", math_format(10^.x))),
  gp[[7]] + theme(legend.position="none") + scale_x_log10( labels = trans_format("log10", math_format(10^.x))), # + ggtitle("2010"),
  gp[[8]] + theme(legend.position="none") + scale_x_log10( labels = trans_format("log10", math_format(10^.x))), # + ggtitle("2010"),
  gp[[9]] + theme(legend.position="none") + scale_x_log10( labels = trans_format("log10", math_format(10^.x))), # + ggtitle("2020"),
  align = 'vh',
  nrow= 2
  )
legend_b <- get_legend(
  gp[[4]] +
    guides(color = guide_legend(nrow = 2)) +
    theme(legend.position = "bottom")
)
pg <- plot_grid(prow, legend_b, nrow = 2, rel_heights = c(1, .1))
save_plot("figure/Amazon_PatchDistr_2003-2008.png",pg,base_width=8,base_height=6,dpi=600)

prow <- plot_grid(
  gp[[10]] + theme(legend.position="none") + scale_x_log10( labels = trans_format("log10", math_format(10^.x))), 
  gp[[11]] + theme(legend.position="none") + scale_x_log10( labels = trans_format("log10", math_format(10^.x))),
  gp[[12]] + theme(legend.position="none") + scale_x_log10(breaks = 10^(0:5), labels = trans_format("log10", math_format(10^.x))),
  gp[[13]] + theme(legend.position="none") + scale_x_log10( labels = trans_format("log10", math_format(10^.x))), # + ggtitle("2010"),
  gp[[14]] + theme(legend.position="none") + scale_x_log10( labels = trans_format("log10", math_format(10^.x))), # + ggtitle("2010"),
  gp[[15]] + theme(legend.position="none") + scale_x_log10( labels = trans_format("log10", math_format(10^.x))), # + ggtitle("2020"),
  align = 'vh',
  nrow= 2
  )
legend_b <- get_legend(
  gp[[4]] +
    guides(color = guide_legend(nrow = 2)) +
    theme(legend.position = "bottom")
)
pg <- plot_grid(prow, legend_b, nrow = 2, rel_heights = c(1, .1))
save_plot("figure/Amazon_PatchDistr_2009-2014.png",pg,base_width=8,base_height=6,dpi=600)


prow <- plot_grid(
  gp[[16]] + theme(legend.position="none") + scale_x_log10( labels = trans_format("log10", math_format(10^.x))), 
  gp[[17]] + theme(legend.position="none") + scale_x_log10( labels = trans_format("log10", math_format(10^.x))),
  gp[[18]] + theme(legend.position="none") + scale_x_log10(breaks = 10^(0:5), labels = trans_format("log10", math_format(10^.x))),
  gp[[19]] + theme(legend.position="none") + scale_x_log10( labels = trans_format("log10", math_format(10^.x))), # + ggtitle("2010"),
  gp[[20]] + theme(legend.position="none") + scale_x_log10( labels = trans_format("log10", math_format(10^.x))), # + ggtitle("2010"),
  gp[[21]] + theme(legend.position="none") + scale_x_log10( labels = trans_format("log10", math_format(10^.x))), # + ggtitle("2020"),
  align = 'vh',
  nrow= 2
  )
legend_b <- get_legend(
  gp[[4]] +
    guides(color = guide_legend(nrow = 2)) +
    theme(legend.position = "bottom")
)
pg <- plot_grid(prow, legend_b, nrow = 2, rel_heights = c(1, .1))
save_plot("figure/Amazon_PatchDistr_2015-2020.png",pg,base_width=8,base_height=6,dpi=600)


#
# Plota annual max size vs tot size
#
require(ggrepel)
p1 <- patch_sizes_p %>% filter(date>2000, date<2022) %>% group_by(date) %>% 
  summarize(max_patch=max(size)/total_forest*100,tot_patch=sum(size)/total_forest*100) %>% 
  mutate( label =as.character(date)) %>%
   ggplot(  aes(max_patch,tot_patch, label=label,color=date ))+ geom_point() + theme_bw() +
      scale_color_viridis_c(guide=NULL)  + 
      xlab("Maximum fire size (%)") +  
      ylab("Total Size (%)") +  
      theme(axis.text.x = element_text(angle = 50, hjust = 1)) + geom_text_repel()
ggplotly(p1)
ggsave("figure/Amazon_Annual_TotSizeVsMaxSize.jpg",plot=p1,width=8,height=6,units="in",dpi=600)


p1 <- patch_sizes_p %>% filter(date>2000, date<2022) %>% group_by(date) %>% 
  summarize(max_patch=max(size)/total_forest*100,tot_patch=sum(size)/total_forest*100) %>% 
  mutate( label =as.character(date)) %>%
   ggplot(  aes(max_patch,tot_patch, label=label,color=date ))+ geom_point(size=2) + theme_bw() +
    geom_curve(curvature = -0.2 , 
                  aes(
                    xend=c(tail(max_patch, n=-1), NA), 
                    yend=c(tail(tot_patch, n=-1), NA)
                  ),
                  arrow=arrow(length=unit(0.2,"cm"))
      ) +
      scale_color_viridis_c(guide=NULL)  + 
      xlab("Maximum fire size (%)") +  
      ylab("Total Size (%)") +  
      theme(axis.text.x = element_text(angle = 50, hjust = 1)) + geom_text_repel()
p1
ggsave("figure/Amazon_Annual_TotSizeVsMaxSize_arrows.jpg",plot=p1,width=8,height=6,units="in",dpi=600)

```

## Proportion of distributions with min AICc 

|type |  n|     expo|    rate|    freq|
|:----|--:|--------:|-------:|-------:|
|ln   |  3| -2.00757| 2.36532| 0.13636|
|pexp | 13|  2.13988| 0.00017| 0.59091|
|pl   |  6|  2.28752|      NA| 0.27273|



# Change of regime

| date  | type  | 1st par.   | 2nd par.   | xmin  | AICc       | range  | Vuong p-value |
| ----: | :---- | ---------: | ---------: | ----: | ---------: | -----: | -----------:  |
| 2001  | ln    | -1.236398  | 2.1531997  | 54    | 6950.870   | 4916   | 0.0029987     |
| 2002  | pexp  | 2.217215   | 0.0002646  | 90    | 8629.256   | 7128   | 0.0000675     |
| 2003  | pexp  | 2.169919   | 0.0005622  | 44    | 14556.177  | 4625   | 0.0000009     |
| 2004  | pexp  | 2.142637   | 0.0001151  | 66    | 13023.416  | 11254  | 0.0000000     |
| 2005  | ln    | -9.180169  | 3.5026064  | 70    | 13842.223  | 13234  | 0.0000000     |
| 2006  | pexp  | 2.041499   | 0.0002795  | 29    | 19285.119  | 3826   | 0.0000000     |
| 2007  | pl    | 2.176596   | NA         | 54    | 15042.315  | 47132  | 0.0002225     |
| 2008  | pexp  | 2.139883   | 0.0002042  | 48    | 10688.426  | 6508   | 0.0000000     |
| 2009  | pl    | 2.400407   | NA         | 45    | 8154.537   | 3117   | 0.0000001     |
| 2010  | pl    | 1.997016   | NA         | 41    | 19977.859  | 75967  | 0.0011222     |
| 2011  | pexp  | 1.954160   | 0.0001630  | 27    | 14112.897  | 10626  | 0.0000000     |
| 2012  | pexp  | 1.981832   | 0.0003285  | 25    | 17126.664  | 3515   | 0.0000000     |
| 2013  | pl    | 2.323158   | NA         | 49    | 6013.017   | 5440   | 0.0001411     |
| 2014  | ln    | -2.007573  | 2.3653178  | 30    | 12775.172  | 7516   | 0.0000675     |
| 2015  | pexp  | 2.262959   | 0.0001455  | 74    | 7857.954   | 5306   | 0.0000031     |
| 2016  | pexp  | 2.111907   | 0.0001705  | 59    | 10315.595  | 5032   | 0.0000000     |
| 2017  | pexp  | 2.035952   | 0.0000956  | 36    | 17060.737  | 10852  | 0.0000000     |
| 2018  | pl    | 2.459423   | NA         | 60    | 5837.460   | 3596   | 0.0000069     |
| 2019  | pexp  | 2.155401   | 0.0000982  | 56    | 11285.548  | 6798   | 0.0000000     |
| 2020  | pl    | 2.251879   | NA         | 86    | 8554.237   | 17718  | 0.0000654     |
| 2021  | pexp  | 2.179439   | 0.0001369  | 63    | 7183.948   | 7311   | 0.0000021     |

1. The years 2009/2013/2018 are year with low total sizes, and 2007/2010/2020 have the high total size, both have power law patch distributions.

2. In contrast the years 2005 have very high number of patches with smaller sizes, no power law distribution

3. These are the extremes in the distribution 

4. The range of power law exponent is 2.00 2.46



# Read precipitation and temperature to screen Data

```{r readFileswithPrecipitationTmaxPatch, echo=FALSE,message=FALSE,warning=FALSE,fig.align='center',eval=FALSE}
require(tidyverse)
require(lubridate)
require(plotly)
# MODIS pixel size
pixelArea <-  463.3127165275 * 463.3127165275
total_area <-  6696597793354.449 # from GEE
total_forest <- 31364191
# 31635980 * pixelArea - 6696597793354.449
# total_forest*pixelArea - 6696597793354.449

region_name <- "Amazon"
patch_size_name <- paste0("Data/patch_size_BurnedArea_",region_name, ".rds")

patch_size <- readRDS(patch_size_name)

pat <- patch_size %>% mutate(date=ymd(date)) %>% group_by(date) %>% 
  summarize(no_patch=n()/total_forest*100,total_patch=sum(size)/total_forest*100,max_patch=max(size)/total_forest*100) 
 
pr <- read_csv("Data/TerraClimatePrAmazonas.csv") %>% inner_join(pat) 

#evi <- read_csv("Data/EVI_by_month_Amazon.csv") %>% mutate(date=strftime(date,"%Y-%m")) %>% group_by(date) %>% summarise(evi=mean(EVI)) %>% mutate(date=ym(date)) 
#pr <- pr %>% inner_join(evi)

p1 <- pr %>% 
  ggplot(  aes(date,pr ))+ geom_line() + theme_bw() +
      scale_color_viridis_c()  + 
      ylab("Accumulated Precitpitation mm") +  
      theme(axis.text.x = element_text(angle = 50, hjust = 1)) +  scale_x_date(date_breaks = "1 year")
ggplotly(p1)


p1 <- pr %>% mutate(pr1=lag(pr,1),pr2=lag(pr,2),pr3=lag(pr,3),pr4=lag(pr,4)) %>% pivot_longer(cols = starts_with("pr"),names_to="lag",values_to = "pp" ) %>%
  ggplot(  aes(pp,total_patch,color=lag ))+ geom_point() + theme_bw() +
      scale_color_viridis_d()  + 
      #ylab("Accumulated Precitpitation mm") +  
      theme(axis.text.x = element_text(angle = 50, hjust = 1)) 
ggplotly(p1)

p1 <- pr %>% mutate(tmmx1=lag(tmmx,1),tmmx2=lag(tmmx,2),tmmx3=lag(tmmx,3),tmmx4=lag(tmmx,4)) %>% pivot_longer(cols = starts_with("tmmx"),names_to="lag",values_to = "pp" ) %>%
  ggplot(  aes(pp,total_patch,color=lag ))+ geom_point() + theme_bw() +
      scale_color_viridis_d()  + 
      xlab("Max temp") +  
      theme(axis.text.x = element_text(angle = 50, hjust = 1)) 
ggplotly(p1)


p1 <- pr %>% 
  ggplot(  aes(pr,max_patch ))+ geom_point() + theme_bw() +
      scale_color_viridis_c()  + 
      #ylab("Accumulated Precitpitation mm") +  
      theme(axis.text.x = element_text(angle = 50, hjust = 1)) 
ggplotly(p1)

```

# Total fire size causality Using Empirical dynamic modelling (dataframe from previous chunk) with maxtemp y monthly precipitation (NOT USED IN THE PAPER)

```{r EDMPatchGrowth, echo=FALSE,message=FALSE,warning=FALSE,fig.align='center',eval=FALSE}
require(rEDM)

#
# Initial analysis of total_patch 
#
simplex_out <- simplex(pr$total_patch)
rho_E <- EmbedDimension(dataFrame=pr, lib="1 242", pred="1 242",columns="total_patch", target="total_patch",maxE=12)
E <- 10
rho_theta_e9 = PredictNonlinear(dataFrame = pr, columns = "total_patch", target = "total_patch", lib = "1 240", pred = "1 240", E = E)

rho_E <- EmbedDimension(dataFrame=pr, lib="1 242", pred="1 242",columns="max_patch", target="max_patch")
E <- 9
rho_theta_e9 = PredictNonlinear(dataFrame = pr, columns = "max_patch", target = "max_patch", lib = "1 242", pred = "1 242", E = E)

rho_E <- EmbedDimension(dataFrame=pr, lib="1 242", pred="1 242",columns="no_patch", target="no_patch",maxE=16)
E <- which.max(rho_E$rho) 
rho_theta_e9 = PredictNonlinear(dataFrame = pr, columns = "no_patch", target = "no_patch", lib = "1 240", pred = "1 240", E = E)

#
rho_Tp <- PredictInterval(dataFrame = pr, lib = "1 121", pred = "122 242", target = "total_patch",
columns = "total_patch", E = 10,maxTp = 20)

simplex = Simplex( dataFrame = pr, 
                   lib     = "1   121", # portion of data to train
                   pred    = "122 242", # portion of data to predict
                   columns = "total_patch",
                   target  = "total_patch",
                   E       = 10,
                   Tp      = 6)

plot( pr$date, pr$total_patch, type = "l", lwd = 2,
      xlab = "year", ylab = "total_patch")
lines( simplex$date, simplex$Predictions, col = "red", lwd = 2)
legend( 'topleft', legend = c( "Observed", "Predicted (year + 1)" ),
        fill = c( 'black', 'red' ), bty = 'n', cex = 1.3 )

err = ComputeError(simplex$Observations, simplex$Predictions)
plot(simplex$Observations, simplex$Predictions, pch = 19, cex = 0.5,xlab = "Observations", ylab = "Predictions", main = "3 Species x_t")
abline(a = 0, b = 1, lty = 2, col = "blue")
text(-1, 1, paste(capture.output(cbind(err)), collapse = "\n"))


Mview = Multiview(dataFrame = pr, lib = "1 121", pred = "122 242", E = 10,
columns = "total_patch pr tmmx", target = "total_patch",Tp=6)

Mview$View  %>% arrange(desc(rho))

plot(Mview$Predictions$Observations, Mview$Predictions$Predictions, pch = 19, cex = 0.5,xlab = "Observations", ylab = "Predictions", main = "Total pr tmmx")
abline(a = 0, b = 1, lty = 2, col = "blue")
text(-1, 1, paste(capture.output(cbind(err)), collapse = "\n"))

plot( Mview$Predictions$date, Mview$Predictions$Observations, type = "l", lwd = 2,
      xlab = "year", ylab = "total_patch")
lines( Mview$Predictions$date, Mview$Predictions$Predictions, col = "red", lwd = 2)
legend( 'topleft', legend = c( "Observed", "Predicted (year + 10)" ),
        fill = c( 'black', 'red' ), bty = 'n', cex = 1.3 )




#
# Convergetn cross mapping 
#
cmap <- CCM(dataFrame = pr, E = 9, Tp = 0, columns = "total_patch",
            target = "pr", libSizes = "10 70 5", sample = 100, showPlot = TRUE)

cmap <- CCM(dataFrame = pr, E = 9, Tp = 0, columns = "total_patch",
            target = "tmmx", libSizes = "10 70 5", sample = 100, showPlot = TRUE)

head(Thrips, 2)

# Embedding dimension
#
rho_E <- EmbedDimension(dataFrame = pr, columns = "total_patch", target = "total_patch",
                        lib = "1 230", pred = "1 230", showPlot = TRUE,maxE=12)
E <- which.max(rho_E$rho)
# Test for nonlinearity
#
rho_theta_e9 = PredictNonlinear(dataFrame = pr, columns = "total_patch", target = "total_patch", lib = "1 230", pred = "1 230", E = E)

# add Seasonal component to pr
ssp <- spectrum(pr$pr)
per <- 1/ssp$freq[ssp$spec==max(ssp$spec)]
pr$t <- 1:nrow(pr)
reslm <- lm(pr ~ sin(2*pi/per*t)+cos(2*pi/per*t),data=pr)
pr$season <-  fitted(reslm)
summary(reslm)

vars <- colnames(pr)[c(5,2,3,8)]

var_pairs = combn(vars, 2) # Combinations of vars, 2 at a time
libSize = paste(NROW(pr) - E, NROW(pr) - E, 10, collapse = " ")
ccm_matrix = array(NA, dim = c(length(vars), length(vars)), dimnames = list(vars,
                                                                            vars))
for (i in 1:ncol(var_pairs)) {
  ccm_out = CCM(dataFrame = pr, columns = var_pairs[1, i], target = var_pairs[2,i], libSizes = libSize, Tp = 0, E = E, sample = 100)
  outVars = names(ccm_out)
  var_out = unlist(strsplit(outVars[2], ":"))
  ccm_matrix[var_out[2], var_out[1]] = ccm_out[1, 2]
  ccm_matrix[var_out[1], var_out[2]] = ccm_out[1, 3]
}


corr_matrix <- array(NA, dim = c(length(vars), length(vars)), dimnames = list(vars,
                                                                              vars))
for (ccm_from in vars) {
  for (ccm_to in vars[vars != ccm_from]) {
    ccf_out <- ccf(pr[, ccm_from], pr[, ccm_to], type = "correlation",
                   lag.max = 6, plot = FALSE)$acf
    corr_matrix[ccm_from, ccm_to] <- max(abs(ccf_out))
  }
}

ccm_matrix
corr_matrix

total_patch_xmap_pr <- CCM(dataFrame = pr, E = E, Tp = 0, columns = "total_patch",
                        target = "pr", libSizes = "15 230 3", sample = 300, showPlot = TRUE)
abline(h = corr_matrix["total_patch", "pr"], col = "black", lty = 2)

total_patch_xmap_tmmx <- CCM(dataFrame = pr, E = E, Tp = 0, columns = "total_patch",
                             target = "tmmx", libSizes = "15 230 3", sample = 300, showPlot = TRUE)
abline(h = corr_matrix["total_patch", "tmmx"], col = "black", lty = 2)

total_patch_xmap_season <- CCM(dataFrame = pr, E = E, Tp = 0, columns = "total_patch",
                        target = "season", libSizes = "15 230 3", sample = 300, showPlot = TRUE)
abline(h = corr_matrix["total_patch", "season"], col = "black", lty = 2)


# data.frame to hold CCM rho values between Thrips abundance and variable
rho_surr <- data.frame(maxT = numeric(1000), Rain = numeric(1000))

# For Precipitation
#
surr_pr = SurrogateData(pr$pr, method = "seasonal", T_period = 12, num_surr = 1000,
                          alpha = 3)

maxT_data = as.data.frame(cbind(seq(1:nrow(pr)), pr$total_patch, surr_pr))
names(maxT_data) = c("time", "total_patch", paste("T", as.character(seq(1, 1000)),
                                                      sep = ""))
# Cross mapping
for (i in 1:1000) {
  targetCol = paste("T", i, sep = "")
  # as in maxT_data
  ccm_out = CCM(dataFrame = maxT_data, E = E, Tp = 0, columns = "total_patch",
                target = targetCol, libSizes = "230 230 5", sample = 1)
  col = paste("total_patch", ":", targetCol, sep = "")
  rho_surr$maxT[i] = ccm_out[1, col]
}
1 - ecdf(rho_surr$maxT)(ccm_matrix["pr", "total_patch"])

# 0.231

# For max Temp
#
surr_pr = SurrogateData(pr$tmmx, method = "seasonal", T_period = 12, num_surr = 1000,
                        alpha = 3)

maxT_data = as.data.frame(cbind(seq(1:nrow(pr)), pr$total_patch, surr_pr))
names(maxT_data) = c("time", "total_patch", paste("T", as.character(seq(1, 1000)),
                                                  sep = ""))
# Cross mapping
for (i in 1:1000) {
  targetCol = paste("T", i, sep = "")
  # as in maxT_data
  ccm_out = CCM(dataFrame = maxT_data, E = E, Tp = 0, columns = "total_patch",
                target = targetCol, libSizes = "230 230 5", sample = 1)
  col = paste("total_patch", ":", targetCol, sep = "")
  rho_surr$maxT[i] = ccm_out[1, col]
}
1 - ecdf(rho_surr$maxT)(ccm_matrix["tmmx", "total_patch"])

# 0 ------------------------->  Significant for temperature 

```


# Load Deforestation Rates from Hansen 2013 

* Plots of previous year % deforestation vs total Fire size

```{r HansendeforestationVsFireSize, echo=FALSE,message=FALSE,warning=FALSE,fig.align='center',eval=FALSE}

require(ggplot2)
require(ggrepel)
#
# Save patch distribution by period
#
patch_size_pfname <- paste0("Data/patch_sizes_p_BurnedArea_", region_name, ".rds" )
if(file.exists(patch_size_pfname)) {
  patch_sizes_p <- readRDS(patch_size_pfname)
} else {
  
  stop("No patch file size by period")
}

#
# Total Area in pixels 31364191
#
total_forest <- 31364191

hansen_def <- read_csv("Data/ForesLossbyYearAmazon.csv") %>% mutate(percent_deforested=loss/totalForestArea)

mean(hansen_def$percent_deforested)
max(hansen_def$percent_deforested)
#
# Mean  0.003765483
# Max   0.007240066
#

p1 <- patch_sizes_p %>% filter(date>2000, date<2023) %>% group_by(date) %>% 
  summarize(max_patch=max(size)/total_forest*100,tot_patch=sum(size)/total_forest*100) %>% 
  mutate( label =as.character(date)) %>% inner_join(hansen_def, by=c("date"="year")) %>% mutate( deforested_prevyear = lag(percent_deforested))


p1 %>% ggplot(  aes(percent_deforested,tot_patch, label=label,color=date ))+ geom_point(size=2) + theme_bw() +
      scale_color_viridis_c(guide=NULL)  + 
      xlab("Annual deforestation (%)") +  
      ylab("Total fire Size (%)") +  
      theme(axis.text.x = element_text(angle = 50, hjust = 1)) + geom_text_repel() 

p1 %>% ggplot(  aes(deforested_prevyear,tot_patch, label=label,color=date ))+ geom_point(size=2) + theme_bw() +
      scale_color_viridis_c(guide=NULL)  + 
      xlab("Previous year annual deforestation (%)") +  
      ylab("Total fire Size (%)") +  
      theme(axis.text.x = element_text(angle = 50, hjust = 1)) + geom_text_repel() 


coeff <- 1/300
p1 %>% ggplot(  aes(date,tot_patch, label=label ))+ geom_line(alpha=0.8,color="red") + theme_bw() +
      scale_color_viridis_c(guide=NULL)  + geom_line(aes(date,percent_deforested/coeff),alpha=0.8) +
      xlab("Annual deforestation (%)") +  
      ylab("Total fire Size (%)") + 
      theme(axis.text.x = element_text(angle = 50, hjust = 1)) +
      scale_y_continuous(
    
      # Features of the first axis
      name = "Annual Fire size",
    
      # Add a second axis and specify its features
      sec.axis = sec_axis(~.*coeff, name="Deforestation")
  )

cor.test(p1$percent_deforested,p1$tot_patch)
cor.test(p1$deforested_prevyear,p1$tot_patch)

#
# Deforestation vs Ignition probability
#
require(lubridate)
ignition_prob <- readRDS("Data/ignition_prob.rds")
p2 <- ignition_prob %>% mutate(year=year(date)) %>% filter(year>2000, year<2023) %>% group_by(year) %>% 
  summarize(bF=mean(bF)) %>% mutate( label =as.character(year)) %>% inner_join(hansen_def, by=c("year"="year")) %>% mutate( deforested_prevyear = lag(percent_deforested))

p2 %>% ggplot(  aes(percent_deforested,bF, label=label,color=year ))+ geom_point(size=2) + theme_bw() +
      scale_color_viridis_c(guide=NULL)  + 
      xlab("Annual deforestation (%)") +  
      ylab("Ignition Probability") +  
      theme(axis.text.x = element_text(angle = 50, hjust = 1)) + geom_text_repel() 

p2 %>% ggplot(  aes(deforested_prevyear,bF, label=label,color=year ))+ geom_point(size=2) + theme_bw() +
      scale_color_viridis_c(guide=NULL)  + 
      xlab("Previous year annual deforestation (%)") +  
      ylab("Ignition Probability") +  
      theme(axis.text.x = element_text(angle = 50, hjust = 1)) + geom_text_repel() 



```
