---
title: "Fit model fire parameters"
output: html_notebook
editor_options: 
  chunk_output_type: console
---

## setup

```{r setup, echo=FALSE,message=FALSE,warning=FALSE,fig.align='center',eval=TRUE}
needed_packages <- c(
    "MASS"
  ,"tidyverse"
  , "lubridate"
  , "nlrx"
  , "tictoc"
  , "future"
  , "poweRlaw"
  , "future.apply"
)
ipak <- function(pkg){
  new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
  if (length(new.pkg))
    install.packages(new.pkg, dependencies = TRUE)
  sapply(pkg, require, character.only = TRUE)
}
ipak(needed_packages)

theme_set(theme_bw())
source("R/functions.r")

# Data Path
#
if( Sys.info()['nodename'] =="ls-pro") {
  
  data_path <- "~/Academicos/GitProjects/AmazonTippingPoint/Data"
} else if(Sys.info()['nodename'] =="biologia2018") {                     # Server UNGS
  data_path <- "~/GitProjects/AmazonTippingPoint/Data"

}


file_pattern <- "^BurnedAreaAmazon20"
fire_bricks <- list.files(path=data_path,pattern=file_pattern)
fire_bricks
region_name  <- str_match(fire_bricks, "^BurnedArea(.*?)20\\d{2}")[1,2]
total_forest <- 31364191

#
# NetLogo 
# Setup for nlrx
#

if( Sys.info()['nodename'] =="ls-pro") {
  simfolder <- "/home/leonardo/Academicos/GitProjects/fireNL"

} else if(Sys.info()['nodename'] =="biologia2018") {                     # Server UNGS
  simfolder <- "/home/leonardo/GitProjects/fireNL"
}


# Unix default NetLogo installation path (adjust to your needs!):
#
netlogopath <- file.path("/home/leonardo/NetLogo")
modelpath <- file.path(simfolder, "DynamicFireForest.nlogo")
outpath <- file.path(simfolder,"Simulations")

# If not defined set the JAVA version of your local 
if(Sys.getenv("JAVA_HOME")==""){
  Sys.setenv(JAVA_HOME = "/usr/lib/jvm/java-11-openjdk-amd64")
  ## "/usr/lib/jvm/java-8-oracle"
}

nl <- nl(nlversion = "6.2",
         nlpath = netlogopath,
         modelpath = modelpath,
         jvmmem = 2048)

```


## Simulations using nlrx

["Fire-probability" 1.3040349103855413E-5]
["increase-fire-prob-seasonality" 10]
["days-fire-season" 90]
["fire-prob-filename" "Data/Estimated_bF.csv"]
["Save-view" false]
["world500x000" false]
["forest-dispersal-distance" 2]
["Forest-growth" 360]
["video" false]
["end-simulation" 14942]
["Initial-forest-density" 0.1]
["Periodicity" false]

# simulations 450x450 

```{r gen_fit_lhs450new06a, echo=FALSE, tidy=TRUE, message=FALSE, warning=FALSE, eval=FALSE}

# A new experiment with a bigger lattice to check size effects
#
nl@experiment <- experiment(expname="Amazon20years450new06a",
                            outpath=outpath,
                            repetition=1,
                            tickmetrics="true",
                            idsetup="setup",
                            idgo="go",
                            idrunnum="nlrx-experiment",
                            runtime=0,
                            metrics=c("Date", "burned-by-month","active-burned","Percent-forest","fire-probability" ),
                            variables = list("forest-dispersal-distance" = list(min=90, max=180, qfun="qunif"),
                                              "Forest-growth" = list(min=365, max=7300, qfun="qunif")),
                            constants = list("world-width" = 449,
                                             "world-height" = 449,
                                               "fire-prob-filename"="\"Data/Estimated_bF.csv\"",
                                               "Save-view" =  "false",
                                               "video" = "false",
                                               "use-fire-prob-se" = "false",
                                               "end-simulation"= 16037,
                                               "Initial-forest-density" = 0.6,
                                               "Periodicity" = "false"
                                             ))

# Add idrunnum as global variable to transfer the current nlrx experiment name, random seed and runnumber (siminputrow) to NetLogo for use with self-written output In NetLogo.


#
# Run 10 times this do not set the run variable for output 
#
#nl@simdesign <- simdesign_simple(nl=nl,
#                               nseeds=2)

#
# Set a latin hypercubic design 
#
nl@simdesign <- simdesign_lhs(nl=nl,
                               samples=100,
                               nseeds=10,
                               precision=2)

# run in Paralell 
#
plan(multisession)
tic()
results <- run_nl_all(nl,split = 4)
toc()
plan(sequential)
names(results)

#
# Write the output 
#
setsim(nl, "simoutput") <- results 
write_simoutput(nl)

```



# simulations 450x450 Expanded set of simulations 

```{r gen_fit_lhs450new03a, echo=FALSE, tidy=TRUE, message=FALSE, warning=FALSE, eval=FALSE}

# A new experiment with a bigger lattice to check size effects
#
nl@experiment <- experiment(expname="Amazon20years450new03a",
                            outpath=outpath,
                            repetition=1,
                            tickmetrics="true",
                            idsetup="setup",
                            idgo="go",
                            idrunnum="nlrx-experiment",
                            runtime=0,
                            metrics=c("Date", "burned-by-month","active-burned","Percent-forest","fire-probability" ),
                            variables = list("forest-dispersal-distance" = list(min=90, max=180, qfun="qunif"),
                                              "Forest-growth" = list(min=365, max=7300, qfun="qunif")),
                            constants = list("world-width" = 449,
                                             "world-height" = 449,
                                               "fire-prob-filename"="\"Data/Estimated_bF.csv\"",
                                               "Save-view" =  "false",
                                               "video" = "false",
                                               "use-fire-prob-se" = "false",
                                               "end-simulation"= 16037,
                                               "Initial-forest-density" = 0.3,
                                               "Periodicity" = "false"
                                             ))


#
# Set a latin hypercubic design 
#
nl@simdesign <- simdesign_lhs(nl=nl,
                               samples=100,
                               nseeds=10,
                               precision=2)

# run in Paralell 
#
plan(multisession)
tic()
results <- run_nl_all(nl,split = 4)
toc()
plan(sequential)
names(results)

#
# Write the output 
#
setsim(nl, "simoutput") <- results 
write_simoutput(nl)

```

# Initial density as a parameter - simulations 450x450 

* I change the name of the experiment e.g. --> expname="Amazon20years450newNorm6"
  to make 1000 simulations each time.

```{r gen_fit_lhs450newNorm6, echo=FALSE, tidy=TRUE, message=FALSE, warning=FALSE, eval=FALSE}

# A new experiment with a bigger lattice to check size effects
#
nl@experiment <- experiment(expname="Amazon20years450newNorm6",
                            outpath=outpath,
                            repetition=1,
                            tickmetrics="true",
                            idsetup="setup",
                            idgo="go",
                            idrunnum="nlrx-experiment",
                            runtime=0,
                            metrics=c("Date", "burned-by-month","active-burned","Percent-forest","fire-probability" ),
                            variables = list("forest-dispersal-distance" = list(min=20, max=290, qfun="qunif"),
                                              "Forest-growth" = list(min=1700, max=1900, qfun="qunif"),
                                              "Initial-forest-density" = list(min=0.2, max=0.7, qfun="qunif")
                                              ),
                            constants = list("world-width" = 449,
                                             "world-height" = 449,
                                               "fire-prob-filename"="\"Data/Estimated_bF.csv\"",
                                               "Save-view" =  "false",
                                               "video" = "false",
                                               "use-fire-prob-se" = "false",
                                               "end-simulation"= 16037,
                                               
                                               "Periodicity" = "false"
                                             ))

# Add idrunnum as global variable to transfer the current nlrx experiment name, random seed and runnumber (siminputrow) to NetLogo for use with self-written output In NetLogo.


#
# Run 10 times this do not set the run variable for output 
#
#nl@simdesign <- simdesign_simple(nl=nl,
#                               nseeds=2)

#
# Set a latin hypercubic design 
#
nl@simdesign <- simdesign_lhs(nl=nl,
                               samples=100,
                               nseeds=10,
                               precision=2)

# run in Paralell 
#
plan(multisession)
tic()
results <- run_nl_all(nl,split = 4)
toc()
plan(sequential)
names(results)

#
# Write the output 
#
setsim(nl, "simoutput") <- results 
write_simoutput(nl)

```

## Previous simulation runs with different lattice size


* Amazon20years249_lhs  - 250x250 lattice size - 18590.67 sec - 5 hs
* Amazon20years349_lhs  - 350x350 lattice size - 
* Amazon20years449_lhs.csv - 450x450
* Amazon20years350_lhs.csv - New simulations with corrected periodic ignition probability 
* Amazon20years450_lhs.csv - 450x450 New simulations with corrected periodic ignition probability 
* Amazon20years450exp01_lhs.csv - 450x450 forest_dispersal_distance= 1.5 -100  Forest-growth=90 -7300 dens_ini=0.6
* Amazon20years450exp02_lhs.csv - 450x450 forest_dispersal_distance=1.5 -100  Forest-growth=90 -7300 dens_ini=0.6
* Amazon20years450exp03_lhs.csv - 450x450 forest_dispersal_distance=1.5 -100  Forest-growth=90 -7300 dens_ini=0.3
* Amazon20years450exp04_lhs.csv - 450x450 forest_dispersal_distance=1.5 -100  Forest-growth=90 -7300 dens_ini=0.3
* Amazon20years450exp05_lhs.csv - 450x450 forest_dispersal_distance=1.5 -100  Forest-growth=90 -7300 dens_ini=0.3

## LHS simulations with initial_forest_density as parameter BORRAR!

* Amazon20years450newDens_lhs.csv - forest_dispersal_distance= 90-180  Forest-growth=365-7300 Initial-forest-density=0.2 - 0.8  
* Amazon20years450newDens1_lhs.csv - forest_dispersal_distance= 90-180  Forest-growth=365-7300 Initial-forest-density=0.2 - 0.8    
* Amazon20years450newDens2_lhs.csv - forest_dispersal_distance= 25-170  Forest-growth=1500-2000 Initial-forest-density=0.4 - 0.8
* Amazon20years450newDens3_lhs.csv - forest_dispersal_distance= 3-180  Forest-growth=1400-2200 Initial-forest-density=0.2 - 0.7
* Amazon20years450newDens4_lhs.csv - forest_dispersal_distance= 3-180  Forest-growth=1400-2200 Initial-forest-density=0.2 - 0.7
* Amazon20years450newDens5_lhs.csv - forest_dispersal_distance= 3-180  Forest-growth=1400-2200 Initial-forest-density=0.2 - 0.7

## LHS simulations with initial_forest_density as parameter

* Amazon20years450newNorm1_lhs.csv # forest_dispersal_distance= 3-180  Forest-growth=365-7300 Initial-forest-density=0.2 - 0.7
* Amazon20years450newNorm2_lhs.csv # forest_dispersal_distance= 3-180  Forest-growth=365-7300 Initial-forest-density=0.2 - 0.7
* Amazon20years450newNorm3_lhs.csv # forest_dispersal_distance= 3-180  Forest-growth=365-7300 Initial-forest-density=0.2 - 0.7

Posterior as prior 

* Amazon20years450newNorm4_lhs.csv # forest_dispersal_distance= 20-290  Forest-growth=1700-1900 Initial-forest-density=0.2 - 0.7
* Amazon20years450newNorm5_lhs.csv # forest_dispersal_distance= 20-290  Forest-growth=1700-1900 Initial-forest-density=0.2 - 0.7
* Amazon20years450newNorm6_lhs.csv # forest_dispersal_distance= 20-290  Forest-growth=1700-1900 Initial-forest-density=0.2 - 0.7



```{r fitModel, echo=FALSE,message=FALSE,warning=FALSE,fig.align='center',eval=FALSE}
require(plotly)

# Read previous simulations
#
if( file.exists("Simulations/Amazon20yearsTot_lhs.rds")) {
  # msim <- readRDS("Simulations/Amazon20yearsTot_lhs.rds") ## Simulated up to 2021-01-01
  
  msim <- readRDS("Simulations/Amazon20yearsTot_lhs.rds") ## Simulated up to 2022-01-01 
  
} else {
  msim <- tibble()
}

msim %>% count(world_width,type)
# msim <- msim %>% filter(type!="iforden")
# msim <- msim %>% mutate(type=if_else(Initial_forest_density==0.3,"ifd_03",type))
# msim <- msim %>% mutate(type=if_else(Initial_forest_density==0.6,"ifd_06",type))

list.files(outpath,"Amazon20years450newNorm.*_lhs\\.csv")
list.files(outpath,"Amazon20years450newDens.*_lhs\\.csv")

# Add a new file with simulations
#


# 
# To rebuild the simulations file you should read all these files I made it one by one because they are big!
#
sim <- read_netlogo_simul(file.path(outpath,"Amazon20years450newNorm1_lhs.csv"),skip=0)
# sim <- read_netlogo_simul(file.path(outpath,"Amazon20years450newNorm2_lhs.csv"),skip=0)
# sim <- read_netlogo_simul(file.path(outpath,"Amazon20years450newNorm3_lhs.csv"),skip=0)
# sim <- read_netlogo_simul(file.path(outpath,"Amazon20years450newNorm4_lhs.csv"),skip=0)
# sim <- read_netlogo_simul(file.path(outpath,"Amazon20years450newNorm5_lhs.csv"),skip=0)
# sim <- read_netlogo_simul(file.path(outpath,"Amazon20years450newNorm6_lhs.csv"),skip=0)

msim0 <- sim %>% filter(Date> "2000-12-31") %>% filter( floor_date(Date, "month") == Date ) %>%
  dplyr::select(world_width,siminputrow,random_seed,Initial_forest_density,forest_dispersal_distance,Forest_growth, Date:fire_probability) %>% mutate(burned_by_month= burned_by_month*100, type="ifd_0207")

nrow(msim0 %>% count(Initial_forest_density,forest_dispersal_distance,Forest_growth))

msim <- bind_rows(msim,msim0)
nrow(msim %>% count(forest_dispersal_distance,random_seed) )

saveRDS(msim,file.path("Simulations","Amazon20yearsTot_lhs.rds"))  

```

## Compare model with data using ABC

* Fitted with Initial_forest_density as parameter  = ifd_0207

```{r abcModel, echo=FALSE,message=FALSE,warning=FALSE,fig.align='center',eval=FALSE}

#
# Retrieve patch file
#
patch_size_name <- paste0("Data/patch_size_BurnedArea_",region_name, ".rds")
if(file.exists(patch_size_name)) {
  patch_size <- readRDS(patch_size_name)
}

total_forest <- 31364191 # total mumber of pixels with forest

mdat <- patch_size %>% mutate(Date=ymd(date)) %>% group_by(Date) %>% 
  summarize(total_patch=sum(size)/total_forest*100) 

#
# Load simulations
#
msim <- readRDS(file.path("Simulations","Amazon20yearsTot_lhs.rds"))  

# ABC to estimate parameters the method loclinear estimated the true parameters in previous test
#
# 21 Years 
# 2001 - 2021 
#
require(abc)
names(mdat)
cc <- mdat %>% mutate(year=year(Date)) %>% filter(year>2000) %>% group_by(year) %>% summarise(max_total_patch=max(total_patch),tot_total_patch=sum(total_patch)) 
ggplot(cc, aes(max_total_patch,tot_total_patch)) + geom_point() + theme_bw()

# Only the vector of max 
#
cc <- mdat %>% mutate(year=year(Date)) %>% filter(year>2000) %>% group_by(year) %>% summarise(max_total_patch=max(total_patch),tot_total_patch=sum(total_patch)) %>% dplyr::select(max_total_patch) %>% deframe()

names(msim)

#
# I Use only type=="ifd_0207" which are the simulations with initial_density as a parameter
#
comp <- msim %>% mutate(year=year(Date)) %>% filter(year<2022,type=="ifd_0207") %>% group_by( type,world_width, siminputrow, random_seed,Initial_forest_density,forest_dispersal_distance, Forest_growth,year) %>% summarize( max_total_patch=max(burned_by_month))

comp <- comp %>% ungroup() %>% pivot_wider(names_from=year,values_from = max_total_patch)
names(comp)
resabc <- abc(target = cc, param=dplyr::select(comp, Initial_forest_density,forest_dispersal_distance, Forest_growth),
    sumstat = dplyr::select(comp, "2001":"2021"), tol = 0.05, method = "rejection" )

summary(resabc)

resabc$unadj.values %>% as_tibble() %>% filter(Initial_forest_density>0 & Initial_forest_density<=1 ) %>% summarise_all(median)

res2 <- abc(target = cc, param=dplyr::select(comp, Initial_forest_density,forest_dispersal_distance, Forest_growth),
    sumstat = dplyr::select(comp, "2001":"2021"), tol = 0.05, method = "loclinear" )

summary(res2)
#
# for type ==ifd_0207

#                        Initial_forest_density forest_dispersal_distance Forest_growth
# Min.:                                 -0.0049                   45.0656     4349.3032
# Weighted 2.5 % Perc.:                  0.0839                   82.9707     4858.3126
# Weighted Median:                       0.2422                  125.6295     6012.1510
# Weighted Mean:                         0.2482                  121.9151     5985.1254
# Weighted Mode:                         0.2112                  129.4196     6181.7635
# Weighted 97.5 % Perc.:                 0.4644                  152.3985     6968.2312
# Max.:                                  0.6251                  163.8599     7765.0649

res2$adj.values %>% as_tibble() %>% filter(Initial_forest_density>0 & Initial_forest_density<=1 ) %>% summarise_all(median)
plot(res2, param=dplyr::select(comp, Initial_forest_density,forest_dispersal_distance, Forest_growth))

#
# Goodness of fit
#
resgfit <- gfit(target=cc, sumstat=dplyr::select(comp, "2001":"2021"),statistic = median, nb.replicate=1000)
plot(resgfit)
summary(resgfit)
# type == ifd_0207 
# $pvalue
# [1] 0.258


#
# Build Table
#
require(rethinking)
tabS6 <- res2$adj.values %>% as_tibble() %>% filter(Initial_forest_density>0 & Initial_forest_density<=1 ) %>% 
  summarise(across(everything(), PI,prob=0.95)) %>% 
  mutate(Name= c("2.5 % Perc.","97.5 % Perc.")) %>% select(Name, everything())

tabS6 <- bind_rows(tabS6,
  res2$adj.values %>% as_tibble() %>% filter(Initial_forest_density>0 & Initial_forest_density<=1 ) %>% 
    summarise(across(everything(), mean)) %>% 
    mutate(Name= c("Mean")) %>% select(Name, everything()),
  res2$adj.values %>% as_tibble() %>% filter(Initial_forest_density>0 & Initial_forest_density<=1 ) %>% 
    summarise(across(everything(), median)) %>% 
    mutate(Name= c("Median")) %>% select(Name, everything())
)

tabS6 <- tabS6[c(1,3,4,2),]
knitr::kable(tabS6, digits = 4)

#
# Add Posterior to data.frame
#
resabc$unadj.values %>% as_tibble() %>% ggplot(aes(forest_dispersal_distance,Initial_forest_density)) + geom_point()
res2$adj.values %>% as_tibble() %>% ggplot(aes(forest_dispersal_distance,Initial_forest_density)) + geom_point()
resabc$unadj.values %>% as_tibble() %>% ggplot(aes(forest_dispersal_distance,Forest_growth)) + geom_point()
res2$adj.values %>% as_tibble() %>% ggplot(aes(forest_dispersal_distance,Forest_growth)) + geom_point()

best <- res2$adj.values %>% as_tibble() %>% mutate(method="loclinear")
best <- bind_rows(best, resabc$unadj.values %>% as_tibble() %>% mutate(method="rejection"))
best <- best %>% mutate(powexp =  (1 - 2 * forest_dispersal_distance ) / (1 - forest_dispersal_distance ))


#
# SAVE the parameter set include initial_density 
#

saveRDS(best,file.path("Simulations","best_Amazon20yearsTot_lhs.rds"))
# best <- readRDS(file.path("Simulations","best_Amazon20yearsTot_lhs.rds"))

set.seed(1325)
plt <- msim %>% inner_join(best  %>% filter(method=="rejection") %>% slice_sample(n=1))%>% inner_join(mdat, by=c("Date" = "Date") ) 
old <- options(pillar.sigfig = 7)
plt %>% distinct(Initial_forest_density, forest_dispersal_distance, Forest_growth)
options(old)

plt %>% 
  ggplot( aes(Date,total_patch ))+ geom_line() + theme_bw() +
      scale_color_viridis_c(guide=FALSE)  + geom_line( aes(Date,burned_by_month,color=random_seed)) +
      ylab("Monthly Burned Size %") +  
      theme(axis.text.x = element_text(angle = 50, hjust = 1)) +  scale_x_date(date_breaks = "1 year") +
      facet_wrap(~random_seed) 
ggsave("figure/Amazon_maxyear_fitted_450.png",width=8,height=6,units="in",dpi=600)

plt %>%  
  ggplot( aes(Date,Percent_forest,color=random_seed) )+ geom_line() + theme_bw() +
      scale_color_viridis_c(guide=FALSE)  +
      ylab("Flammable Forest density") +  
      theme(axis.text.x = element_text(angle = 50, hjust = 1)) +  scale_x_date(date_breaks = "1 year") +  facet_wrap(~random_seed)

plt %>%  
  ggplot( aes(Date,Percent_forest) )+ geom_line(alpha=0.4,color=colnet[1]) + theme_bw() +
      scale_color_viridis_c(guide=FALSE)  +
      ylab("Flammable Forest density") +  
      theme(axis.text.x = element_text(angle = 50, hjust = 1)) +  scale_x_date(date_breaks = "1 year") 
ggsave("figure/Amazon_forestDens_fitted_450.png",width=8,height=6,units="in",dpi=600)


# Plot all simulations as dots, set  slice_sample(n=10)
#
require(rethinking)
plt <- msim %>% inner_join(best  %>% filter(method=="rejection") )%>% inner_join(mdat, by=c("Date" = "Date") ) %>% group_by(Date) %>% summarise(min_burned_by_month=PI(burned_by_month,prob=0.95)[1],max_burned_by_month=PI(burned_by_month,prob=0.95)[2],total_patch=max(total_patch))


require(viridis)
colnet <- viridis(3)
#
# Shifted 3 months and the peaks coincide!!
n <- 3
plt %>%  
  ggplot( aes(Date,total_patch ))+ geom_line() + theme_bw() +
      scale_color_viridis_c(guide=FALSE)  + 
      geom_ribbon( aes(ymin=lead(min_burned_by_month,n),ymax=lead(max_burned_by_month,n)),alpha=0.4) +
      ylab("Monthly Burned Size %") +  
      theme(axis.text.x = element_text(angle = 50, hjust = 1)) +  scale_x_date(date_breaks = "1 year") 


plt %>%  
  ggplot( aes(Date,total_patch ))+ geom_line() + theme_bw() +
      scale_color_viridis_c(guide=FALSE)  + 
      geom_ribbon( aes(ymin=min_burned_by_month,ymax=max_burned_by_month),alpha=0.4) +
      ylab("Monthly Burned Size %") +  
      theme(axis.text.x = element_text(angle = 50, hjust = 1)) +  scale_x_date(date_breaks = "1 year") 
ggsave("figure/Amazon_maxyear_PI95_450.png",width=8,height=6,units="in",dpi=600)



#
# Yearly comparison of predicted vs data (Max)
#
plt <- msim %>% inner_join(best  %>% filter(method=="rejection") %>% distinct() )%>% inner_join(mdat, by=c("Date" = "Date") ) %>%  mutate(year=year(Date)) %>% group_by(forest_dispersal_distance,year,random_seed) %>%  summarise(sum_burned=sum(burned_by_month),sum_patch=sum(total_patch),sd_burned=sd(burned_by_month)) 

plt %>% ggplot(  aes(sum_burned,sum_patch ))+ geom_point(alpha=0.1) + theme_bw() + xlab("Predicted") + ylab("Data") + 
      #geom_errorbarh(aes(xmax=sum_burned+sd_burned,xmin=sum_burned-sd_burned)) + 
      scale_color_viridis_d(guide=NULL)  + geom_abline(intercept = 0, slope =1,alpha=0.3) #+ coord_cartesian(xlim=c(0,1.5)) 
ggsave("figure/Amazon_maxyear_dataVsPredicted_450.png",width=8,height=6,units="in",dpi=600)

plt %>% ggplot(  aes(year,sum_patch ))+ geom_point(alpha=0.1) + theme_bw() + xlab("Year") + ylab("Data") + 
      geom_jitter(aes(year,sum_burned),alpha=0.1,color=colnet[1]) + 
      scale_color_viridis_d(guide=NULL)  + geom_abline(intercept = 0, slope =1,alpha=0.3) #+ coord_cartesian(xlim=c(0,1.5)) 

ggsave("figure/Amazon_maxyear_dataVsPredicted_jitter.png",width=8,height=6,units="in",dpi=600)


```

## Model Fit using ABC and the max monthly fire size of the year

### Files with the performed simulations

[1] "Amazon20years450newNorm1_lhs.csv" "Amazon20years450newNorm2_lhs.csv" "Amazon20years450newNorm3_lhs.csv" "Amazon20years450newNorm4_lhs.csv"
[5] "Amazon20years450newNorm5_lhs.csv" "Amazon20years450newNorm6_lhs.csv"

### ABC Rejection method (median) 

    Initial_forest_density forest_dispersal_distance Forest_growth
                   <dbl>                     <dbl>         <dbl>
1                   0.29                      101.         5091.


### ABC Loclinear method (median)

    Initial_forest_density forest_dispersal_distance Forest_growth
                   <dbl>                     <dbl>         <dbl>
1                  0.274                      123.         5842.


## Simulations with patch size output for wordl_width = 450 

* Sample 300 parameters from the posterior then make new simulations to estimate the patch size distributions
* Have to run this in chunks of 50,100,100,50 because it was the only way of doing it, it seems that netlogo/java hangs
* So I generated files with names Amazon20years450Post50, Amazon20years450Post150...

```{r sim_distinct449Amazon20yearPost300, echo=FALSE, tidy=TRUE, message=FALSE, warning=FALSE, eval=FALSE}

best <- readRDS(file.path("Simulations","best_Amazon20yearsTot_lhs.rds"))


disp_best <- best %>% filter( method=="loclinear", forest_dispersal_distance>0 ) %>% ungroup() %>% dplyr::select(forest_dispersal_distance) %>% deframe()
grow_best <- best %>% filter( method=="loclinear", forest_dispersal_distance>0 ) %>% ungroup() %>% dplyr::select(Forest_growth) %>% deframe()
ini_best  <- best %>% filter( method=="loclinear", forest_dispersal_distance>0 )%>% ungroup() %>% dplyr::select(Initial_forest_density) %>% deframe()

# Check
round(median(ini_best),3) == 0.274
length(disp_best)==300

# first 100
disp_best <- disp_best[251:300]
grow_best <- grow_best[251:300]
ini_best <- ini_best[251:300]

eval_times <- as.numeric(lapply(1:21, function(x){ymd("2000-12-31") + years(x) - ymd("1980-11-01") }))
ymd("1980-11-01") + days(eval_times)

nl@experiment <- experiment(expname="Amazon20years450Post300",
                            outpath=outpath,
                            repetition=1,
                            tickmetrics="true",
                            idsetup="setup",
                            idgo="go",
                            #idrunnum="nlrx-experiment",
                            runtime=0,
                            evalticks=eval_times,          # ymd("2011-12-31")  - ymd("1980-11-01") + 0:19
                            metrics=c("Date", "burned-by-month","active-burned","Percent-forest","fire-probability","burned-clusters 365", "median-fire-interval" ),
                            variables = list("forest-dispersal-distance" = list(values=disp_best),
                                             "Forest-growth" = list(values=grow_best),
                                             "Initial-forest-density" = list(values=ini_best)
                                             ),
                            constants = list("world-width" = 449,
                                             "world-height" = 449,
                                               "fire-prob-filename"="\"Data/Estimated_bF.csv\"",
                                               "Save-view" =  "false",
                                               "video" = "false",
                                               "end-simulation"= 15037,
                                               "use-fire-prob-se" = "false",
                                               "Periodicity" = "false",
                                               "Fire-probability" = 1E-6,
                                               "eval-burned-clusters"=paste0("\"[",paste(eval_times,collapse=" "),"]\"")
                                             ))


#
# Run 10 times this do not set the run variable for output 
#
# Total number of jobs = nseeds * split = 10*4 
# Each job runs parameter input matrix / split = nrow(nl@simdesign@siminput) / split =  300 / 4 
#

nl@simdesign <- simdesign_distinct(nl=nl,
                               nseeds=10)

# run in Paralell 
#
plan(multisession)
tic()
results <- run_nl_all(nl,split = 5)
toc()
plan(sequential)
names(results)

#
# Write the output 
#
setsim(nl, "simoutput") <- results 
write_simoutput(nl)

```

# Cluster distribution comparison 

* We  estimated the fire patch distributions for the posterior of 1st ABC 


```{r calc_powlaw_450cluster21-300, echo=FALSE, tidy=TRUE, message=FALSE, warning=FALSE, eval=FALSE}

# Read previously saved fitted exponents file
#
pexp_name <- file.path("Simulations", "fittedExponentsAmazon21post.rds")
if(file.exists(pexp_name)) {
  pexp <- readRDS(pexp_name)
  pexp %>% distinct(world_width,sim_type)

} else {
  pexp <- tibble()
}
  
list.files(outpath,"Amazon20years450Post.*\\.csv")


sim <- read_netlogo_simul(file.path(outpath,"Amazon20years450Post50_distinct.csv"),skip=0)
sim <- bind_rows(sim,read_netlogo_simul(file.path(outpath,"Amazon20years450Post150_distinct.csv"),skip=0))
sim <- bind_rows(sim,read_netlogo_simul(file.path(outpath,"Amazon20years450Post250_distinct.csv"),skip=0))
sim <- bind_rows(sim,read_netlogo_simul(file.path(outpath,"Amazon20years450Post300_distinct.csv"),skip=0))


plan(multisession)
p_df <- future_lapply( 1:nrow(sim) , function(i){
  df <- netlogo_evaluate_patch_distr(sim$burned_clusters_365[i]) %>%
    mutate(Initial_forest_density=sim$Initial_forest_density[i], forest_dispersal_distance=sim$forest_dispersal_distance[i],Forest_growth=sim$Forest_growth[i],Date=sim$Date[i],random_seed=sim$random_seed[i],
           Percent_forest=sim$Percent_forest[i]) %>%
    dplyr::select(Initial_forest_density,forest_dispersal_distance,Forest_growth,Date,random_seed, everything()) 
})
pexp <- bind_rows(pexp,p_df)
plan(sequential)

saveRDS(pexp, file.path("Simulations", "fittedExponentsAmazon21post.rds"))
```

# Cluster distribution comparison 

* Use ABC to compare cluster size distribution from data 


```{r comp_fit_lhs450cluster21-300, echo=FALSE, tidy=TRUE, message=FALSE, warning=FALSE, eval=FALSE}

# Read previously saved fitted exponents file
pexp <- readRDS( file.path("Simulations", "fittedExponentsAmazon21post.rds"))

best_pexp <- pexp %>% group_by(Initial_forest_density,forest_dispersal_distance,Forest_growth,Date,random_seed) %>% fill(range) %>% mutate(delta = AICc - min(AICc), rel_lik=exp(-0.5 * delta),prob_model=round(rel_lik/sum(rel_lik),2)) %>% dplyr::select(-c(date)) %>% filter(delta==0)


# 
# Best distributions with AIC
#
knitr::kable(best_pexp %>% group_by(type) %>% summarise(n = n(),expo=median(expo)) %>%  mutate(freq = n / sum(n)), digits = 3)

pl_best_pexp <- best_pexp %>% filter(type == "pl") # %>% mutate(relative_range=range/(350*350))

plt <- pl_best_pexp %>% group_by(Initial_forest_density,forest_dispersal_distance,Forest_growth) %>% summarize(pimin=PI(expo,prob=0.95)[1],pimax=PI(expo,prob=0.95)[2],expo=median(expo)) 


p1 <- plt %>% ggplot( aes(x=forest_dispersal_distance, y=expo)) + 
    geom_linerange(aes(ymin=pimin, ymax=pimax)) +
    geom_point() + geom_hline(yintercept=2.29, linetype="dashed", 
                color = "red", size=1)

p2 <- plt %>% ggplot( aes(x=Forest_growth, y=expo)) + 
    geom_linerange(aes(ymin=pimin, ymax=pimax), width=.1) +
    geom_point() + geom_hline(yintercept=2.29, linetype="dashed", 
                color = "red", size=1)

p3 <- plt %>% ggplot( aes(x=Initial_forest_density, y=expo)) + 
    geom_linerange(aes(ymin=pimin, ymax=pimax)) +
    geom_point() + geom_hline(yintercept=2.29, linetype="dashed", 
                color = "red", size=1)

require(ggpubr)
ggarrange(p1,p2 + theme(axis.text.y=element_blank(),axis.title.y=element_blank()),
          p3, widths = c(1.1,1))
ggsave("figure/Amazon_1stABC_post_params.png",width=8,height=6,units="in",dpi=600)

#
# ABC for power law exponent
#
require(abc)
cc <- 2.29
comp <- pl_best_pexp %>% ungroup()
resabc <- abc(target = cc, param=dplyr::select(comp, Initial_forest_density,forest_dispersal_distance, Forest_growth),
    sumstat = dplyr::select(comp, expo), tol = 0.05, method = "rejection" )
summary(resabc)

res2 <- abc(target = cc, param=dplyr::select(comp, Initial_forest_density,forest_dispersal_distance, Forest_growth),
    sumstat = dplyr::select(comp, expo), tol = 0.05, method = "loclinear" )
summary(res2)
plot(res2, param=dplyr::select(comp, Initial_forest_density,forest_dispersal_distance, Forest_growth))

#
# Goodness of fit: each simulation is taken as pseudo-observed dataset, and the rejection algorithm is performed
#                  to obtain the g.o.f statistic (median).
#
resgfit <- gfit(target=cc, sumstat=dplyr::select(comp,expo),statistic = median, nb.replicate=1000)
plot(resgfit)
summary(resgfit)
# $pvalue
# [1] 0.964

# Build Table S7
#
require(rethinking)
tabS7 <- res2$adj.values %>% as_tibble() %>% filter(Initial_forest_density>0 & Initial_forest_density<=1 ) %>% 
  summarise(across(everything(), PI,prob=0.95)) %>% 
  mutate(Name= c("2.5 % Perc.","97.5 % Perc.")) %>% select(Name, everything())

tabS7 <- bind_rows(tabS7,
  res2$adj.values %>% as_tibble() %>% filter(Initial_forest_density>0 & Initial_forest_density<=1 ) %>% 
    summarise(across(everything(), mean)) %>% 
    mutate(Name= c("Mean")) %>% select(Name, everything()),
  res2$adj.values %>% as_tibble() %>% filter(Initial_forest_density>0 & Initial_forest_density<=1 ) %>% 
    summarise(across(everything(), median)) %>% 
    mutate(Name= c("Median")) %>% select(Name, everything())
)


knitr::kable(tabS7[c(1,3,4,2),], digits = 4)

best_parm <- res2$adj.values %>% as_tibble() %>% mutate(method="loclinear") %>% filter(Initial_forest_density>0)
best_parm <- bind_rows(best_parm, resabc$unadj.values %>% as_tibble() %>% mutate(method="rejection"))
best_parm <- best_parm %>% mutate(powexp =  (1 - 2 * forest_dispersal_distance ) / (1 - forest_dispersal_distance ))

saveRDS(best_parm, file.path("Simulations", "bestFittedExponentsAmazon21yearsPost.rds"))

#
# Mean of posteriori with theta calculated with the mean ignition probability
#

# Read ignition probability
ignition_prob <- readRDS("Data/ignition_prob.rds") 

meanBf <- round(mean(ignition_prob$bF),7)                 # test the mean value = 8.43e-05

rangeBf <- round(range(ignition_prob$bF),7)

knitr::kable( best_parm %>% mutate(mean_theta = 1/(Forest_growth * meanBf / 30 ), max_theta=  1/(Forest_growth * rangeBf[1] / 30 ), min_theta=  1/(Forest_growth * rangeBf[2] / 30 )) %>% group_by(method) %>% summarise(across(where(is.numeric),mean)), digits = 4)


# |method    | Initial_forest_density| forest_dispersal_distance| Forest_growth| powexp| mean_theta| max_theta|
# |:---------|----------------------:|-------------------------:|-------------:|------:|----------:|---------:|
# |loclinear |                 0.2706|                  119.5919|       5835.70| 2.0087|    61.5630|  910.4842|
# |rejection |                 0.2641|                  119.6898|       5846.39| 2.0087|    61.4486|  908.7926|  

#
# Plots of Theta with the mean a posteriori Forest_growth = 1776
#
ignition_prob <- readRDS("Data/ignition_prob.rds") 

mean_Forest_growth <- best_parm %>% filter(method=="loclinear") %>% summarise(mean_Forest_growth=mean(Forest_growth)) %>% deframe()

ignition_prob %>% mutate(Date=ymd(date),theta = 1/(mean_Forest_growth * bF / 30 ) ) %>% ggplot( aes(Date,theta ))+ geom_line() + theme_bw() +
      scale_color_viridis_c(guide="none")  +
      ylab("Theta") +  
      theme(axis.text.x = element_text(angle = 50, hjust = 1)) +  scale_x_date(date_breaks = "1 year") 
ggsave("figure/Amazon_Theta_fitted_450.png",width=8,height=6,units="in",dpi=600)

ignition_prob <- read_csv( "Data/EstimatedGam_bF.csv") 
ignition_prob %>% filter(date >= "2000-01-01") %>% mutate(theta = 1/(mean_Forest_growth * fit / 30 ) ) %>% ggplot( aes(date,theta ))+ geom_line() + theme_bw() +
      scale_color_viridis_c(guide=FALSE)  +
      ylab("Theta") +  
      theme(axis.text.x = element_text(angle = 50, hjust = 1)) +  scale_x_date(date_breaks = "1 year") 

```


* Frequency of distributions with lower AICc 

* Data
|type |  n|     expo|    rate|    freq|
|:----|--:|--------:|-------:|-------:|
|ln   |  3| -2.00757| 2.36532| 0.13636|
|pexp | 13|  2.13988| 0.00017| 0.59091|
|pl   |  6|  2.28752|      NA| 0.27273|

* Model
|type |     n|    expo|  freq|
|:----|-----:|-------:|-----:|
|exp  |  4670|   0.057| 0.074|
|ln   | 15946| -68.175| 0.254|
|pexp | 33862|   1.430| 0.540|
|pl   |  8244|   2.728| 0.131|



* Mean of a posteriori parameter distribution 

|method    | Initial_forest_density| forest_dispersal_distance| Forest_growth| powexp| mean_theta| max_theta|
|:---------|----------------------:|-------------------------:|-------------:|------:|----------:|---------:|
|loclinear |                 0.2706|                  119.5919|       5835.70| 2.0087|    61.5630|  910.4842|
|rejection |                 0.2641|                  119.6898|       5846.39| 2.0087|    61.4486|  908.7926|  




# Simulations with best parameters a posteriori mean theta 61 max 909 


* 100 parameters from posterior 

```{r sim_distinct449clusterPostTheta61, echo=FALSE, tidy=TRUE, message=FALSE, warning=FALSE, eval=FALSE}

best <- readRDS(file.path("Simulations","bestFittedExponentsAmazon21yearsPost.rds")) %>% filter(method=="loclinear")

disp_best <- best %>% dplyr::select(forest_dispersal_distance) %>% deframe()
grow_best <- best %>% ungroup() %>% dplyr::select(Forest_growth) %>% deframe()
ini_best  <- best %>% ungroup() %>% dplyr::select(Initial_forest_density) %>% deframe()
disp_best <- disp_best[1:100]
grow_best <- grow_best[1:100]
ini_best <- ini_best[1:100]


eval_times <- as.numeric(lapply(1:21, function(x){ymd("2000-12-31") + years(x) - ymd("1980-11-01") }))
ymd("1980-11-01") + days(eval_times)

nl@experiment <- experiment(expname="Amazon21years449postTheta61",
                            outpath=outpath,
                            repetition=1,
                            tickmetrics="true",
                            idsetup="setup",
                            idgo="go",
                            #idrunnum="nlrx-experiment",
                            runtime=0,
                            evalticks=eval_times,          # ymd("2011-12-31")  - ymd("1980-11-01") + 0:19
                            metrics=c("Date", "burned-by-month","active-burned","Percent-forest","fire-probability","burned-clusters 365", "median-fire-interval" ),
                            variables = list("forest-dispersal-distance" = list(values=disp_best),
                                             "Forest-growth" = list(values=grow_best),
                                             "Initial-forest-density" = list(values=ini_best)
                            ),
                            constants = list("world-width" = 449,
                                             "world-height" = 449,
                                               "fire-prob-filename"="\"Data/Estimated_bF.csv\"",
                                               "Save-view" =  "false",
                                               "video" = "false",
                                               "end-simulation"= 15037,
                                               "use-fire-prob-se" = "false",
                                               "Periodicity" = "false",
                                               "Fire-probability" = 1E-6,
                                               "eval-burned-clusters"=paste0("\"[",paste(eval_times,collapse=" "),"]\"")
                                             ))


#
# Total number of jobs = nseeds * split = 10*4 
# Each job runs parameter input matrix / split = nrow(nl@simdesign@siminput) / split =  300 / 4 
#

nl@simdesign <- simdesign_distinct(nl=nl,
                               nseeds=10)

# run in Paralell 
#
plan(multisession)
tic()
results <- run_nl_all(nl,split = 4)
toc()
plan(sequential)
names(results)

#
# Write the output 
#
setsim(nl, "simoutput") <- results 
write_simoutput(nl)
```

## Calc exponents best fitted with estimatee GAM ignition, wordl_width = 450 -  theta 61

```{r calcPatchDist450_PostTheta61, echo=FALSE,message=FALSE,warning=FALSE,fig.align='center',eval=FALSE}

list.files(outpath,"Amazon21years449post.*\\.csv")

# Calculate patch distributions from best fitted parameters and GAM estimated bF (ignition prob) 2000-2020

# Read previous simulations for RCP 4.5 and fitted parameters
#
sim <- read_netlogo_simul(file.path(outpath,"Amazon21years449postTheta61_distinct.csv"),skip=0)
# Calculate power law exponents and max/total patch size by year 
#
pexp <- tibble()

plan(multisession)
p_df <- future_lapply( 1:nrow(sim) , function(i){
  df <- netlogo_evaluate_patch_distr(sim$burned_clusters_365[i]) %>%
    mutate(Initial_forest_density=sim$Initial_forest_density[i], forest_dispersal_distance=sim$forest_dispersal_distance[i],Forest_growth=sim$Forest_growth[i],Date=sim$Date[i],random_seed=sim$random_seed[i],
           Percent_forest=sim$Percent_forest[i]) %>%
    dplyr::select(Initial_forest_density,forest_dispersal_distance,Forest_growth,Date,random_seed, everything()) 
})
pexp <- bind_rows(pexp,p_df)
plan(sequential)

saveRDS(pexp, file.path("Simulations", "simExponentsAmazonPostTheta61.rds"))
```

## Plot 2nd ABC fitted parameters

```{r plotParameters450_PostTheta61, echo=FALSE,message=FALSE,warning=FALSE,fig.align='center',eval=FALSE}
require(rethinking)
# Read previously saved fitted exponents file
pexp <- readRDS( file.path("Simulations", "simExponentsAmazonPostfittedBF.rds"))
# pexp <- readRDS( file.path("Simulations", "simExponentsAmazonPostTheta61.rds"))

best_pexp <- pexp %>% group_by(Initial_forest_density,forest_dispersal_distance,Forest_growth,Date,random_seed) %>% fill(range) %>% mutate(delta = AICc - min(AICc), rel_lik=exp(-0.5 * delta),prob_model=round(rel_lik/sum(rel_lik),2)) %>% dplyr::select(-c(date)) %>% filter(delta==0)


# 
# Best distributions with AIC
#
knitr::kable(best_pexp %>% group_by(type) %>% summarise(n = n(),expo=median(expo)) %>%  mutate(freq = n / sum(n)), digits = 3)

pl_best_pexp <- best_pexp %>% filter(type == "pl") # %>% mutate(relative_range=range/(350*350))

plt <- pl_best_pexp %>% group_by(Initial_forest_density,forest_dispersal_distance,Forest_growth) %>% summarize(pimin=PI(expo,prob=0.95)[1],pimax=PI(expo,prob=0.95)[2],expo=median(expo)) 

p1 <-plt %>% ggplot( aes(x=forest_dispersal_distance, y=expo)) + 
    geom_linerange(aes(ymin=pimin, ymax=pimax)) +
    geom_point() + geom_hline(yintercept=2.29, linetype="dashed", 
                color = "red", size=1) + xlab("Dispersal Distance") + ylab("Fire size power law exponent")


p2 <-plt %>% ggplot( aes(x=Forest_growth, y=expo)) + 
    geom_linerange(aes(ymin=pimin, ymax=pimax)) +
    geom_point() + geom_hline(yintercept=2.29, linetype="dashed", 
                color = "red", size=1) + xlab("Forest growth") + ylab("Fire size power law exponent")

p3 <- plt %>% ggplot( aes(x=Initial_forest_density, y=expo)) + 
    geom_linerange(aes(ymin=pimin, ymax=pimax)) +
    geom_point() + geom_hline(yintercept=2.29, linetype="dashed", 
                color = "red", size=1) + xlab("Initial Density") + ylab("Fire size power law exponent")

# Vertical plot
#
pl_best_pexp %>% ungroup() %>%summarize(pimin=PI(expo,prob=0.95)[1],pimax=PI(expo,prob=0.95)[2],expo=median(expo)) %>% mutate(id=factor(row_number())) %>% ggplot( aes(y=id, x=expo)) + 
    geom_linerange(aes(xmin=pimin, xmax=pimax)) + 
    geom_point() + geom_vline(xintercept=2.29, linetype="dashed", 
                color = "red", size=1) + ylab("Parameter set") + xlab("Fire size power law exponent")


require(ggpubr)
ggarrange(p1,p2 + theme(axis.text.y=element_blank(),axis.title.y=element_blank()),
          p3, widths = c(1.1,1))
ggsave("figure/Amazon_2ndABC_post_params.png",width=8,height=6,units="in",dpi=600)

# To add to table 
#
pl_best_pexp %>% ungroup() %>% summarize(pimin=PI(expo,prob=0.95)[1],pimax=PI(expo,prob=0.95)[2],Median=median(expo),Mean=mean(expo)) 


```

# Simulations with the fitted bF GAM for the data period - theta 61


```{r sim_simple449Post_gamBF61, echo=FALSE, tidy=TRUE, message=FALSE, warning=FALSE, eval=FALSE}

best <- readRDS(file.path("Simulations","bestFittedExponentsAmazon21yearsPost.rds"))

disp_best <- best %>% dplyr::select(forest_dispersal_distance) %>% deframe()
grow_best <- best %>% ungroup() %>% dplyr::select(Forest_growth) %>% deframe()
ini_best  <- best %>% ungroup() %>% dplyr::select(Initial_forest_density) %>% deframe()
disp_best <- disp_best[1:100]
grow_best <- grow_best[1:100]
ini_best <- ini_best[1:100]


eval_times <- as.numeric(lapply(1:21, function(x){ymd("2000-12-31") + years(x) - ymd("1980-11-01") }))
ymd("1980-11-01") + days(eval_times)

nl@experiment <- experiment(expname="Amazon21years449PostfittedBF",
                            outpath=outpath,
                            repetition=1,
                            tickmetrics="true",
                            idsetup="setup",
                            idgo="go",
                            #idrunnum="nlrx-experiment",
                            runtime=0,
                            evalticks=eval_times,          # ymd("2011-12-31")  - ymd("1980-11-01") + 0:19
                            metrics=c("Date", "burned-by-month","active-burned","Percent-forest","fire-probability","burned-clusters 365", "median-fire-interval" ),
                            variables = list("forest-dispersal-distance" = list(values=disp_best),
                                             "Forest-growth" = list(values=grow_best),
                                             "Initial-forest-density" = list(values=ini_best)
                            ),
                            constants = list("world-width" = 449,
                                             "world-height" = 449,
                                               "fire-prob-filename"="\"Data/EstimatedGam_bF.csv\"",
                                               "Save-view" =  "false",
                                               "video" = "false",
                                               "end-simulation"= 15037,
                                               "use-fire-prob-se" = "false",
                                               "Periodicity" = "false",
                                               "Fire-probability" = 1E-6,
                                               "eval-burned-clusters"=paste0("\"[",paste(eval_times,collapse=" "),"]\"")
                                             ))

#
# Total number of jobs = nseeds * split = 10*4 
# Each job runs parameter input matrix / split = nrow(nl@simdesign@siminput) / split =  300 / 4 
#
nl@simdesign <- simdesign_distinct(nl=nl,
                               nseeds=10)
# 
# nl@simdesign <- simdesign_distinct(nl=nl,
#                                nseeds=50)

# run in Paralell 
#
plan(multisession)
tic()
results <- run_nl_all(nl,split = 4)
toc()
plan(sequential)
names(results)

#
# Write the output 
#
setsim(nl, "simoutput") <- results 
write_simoutput(nl)

```

# Calculate patch distributions from best fitted parameters and GAM estimated bF (ignition prob) 2000-2020

```{r calcPatchDist449_PostgamBF21, echo=FALSE,message=FALSE,warning=FALSE,fig.align='center',eval=FALSE}


# Read previous simulations for gam bF and fitted parameters
#
list.files(outpath)
sim <- read_netlogo_simul(file.path(outpath,"Amazon21years449PostfittedBF_distinct.csv"),skip=0)
# Calculate power law exponents and max/total patch size by year 
#
pexp <- tibble()

plan(multisession)
p_df <- future_lapply( 1:nrow(sim) , function(i){
  df <- netlogo_evaluate_patch_distr(sim$burned_clusters_365[i]) %>%
    mutate(Initial_forest_density=sim$Initial_forest_density[i], forest_dispersal_distance=sim$forest_dispersal_distance[i],Forest_growth=sim$Forest_growth[i],Date=sim$Date[i],random_seed=sim$random_seed[i],
           Percent_forest=sim$Percent_forest[i]) %>%
    dplyr::select(Initial_forest_density,forest_dispersal_distance,Forest_growth,Date,random_seed, everything()) 
})
pexp <- bind_rows(p_df)
plan(sequential)



saveRDS(pexp, file.path("Simulations", "simExponentsAmazonPostfittedBF.rds"))
```

# Simulations with best parameters and patch size distribution RCP 4.5 (2021 - 2059)

* wordl_width = 450 
* RCP 4.5
* Have to run the first 40 [1:40] and then the last 60 [41:100] so I generated to files

```{r sim_simple449postRCP45_amazon59_60, echo=FALSE, tidy=TRUE, message=FALSE, warning=FALSE, eval=FALSE}

best <- readRDS(file.path("Simulations","bestFittedExponentsAmazon21yearsPost.rds"))

disp_best <- best %>% dplyr::select(forest_dispersal_distance) %>% deframe()
grow_best <- best %>% ungroup() %>% dplyr::select(Forest_growth) %>% deframe()
ini_best  <- best %>% ungroup() %>% dplyr::select(Initial_forest_density) %>% deframe()
disp_best <- disp_best[41:100]
grow_best <- grow_best[41:100]
ini_best <- ini_best[41:100]
# eval_times <- as.numeric(lapply(0:9, function(x){ymd("2011-12-31") + years(x) - ymd("1980-11-01") }))
# ymd("1980-11-01") + days(eval_times)

eval_times <- as.numeric(lapply(0:58, function(x){ymd("2001-12-31") + years(x) - ymd("1980-11-01") }))
ymd("1980-11-01") + days(eval_times)

nl@experiment <- experiment(expname="Amazon59years449PostRcp45_60",
                            outpath=outpath,
                            repetition=1,
                            tickmetrics="true",
                            idsetup="setup",
                            idgo="go",
                            #idrunnum="nlrx-experiment",
                            runtime=0,
                            evalticks= eval_times,          # ymd("2011-12-31")  - ymd("1980-11-01") + 1
                            metrics=c("Date", "burned-by-month","active-burned","Percent-forest","fire-probability","burned-clusters 365","median-fire-interval" ),
                            variables = list("forest-dispersal-distance" = list(values=disp_best),
                                             "Forest-growth" = list(values=grow_best),
                                             "Initial-forest-density" = list(values=ini_best)
                            ),
                            constants = list("world-width" = 449,
                                             "world-height" = 449,
                                               "fire-prob-filename"="\"Data/Predicted_bF_rcp45.csv\"",
                                               "Save-view" =  "false",
                                               "video" = "false",
                                               "end-simulation"= 28918,
                                               "Periodicity" = "false",
                                               "Fire-probability" = 1E-6,
                                               "eval-burned-clusters"=paste0("\"[",paste(eval_times,collapse=" "),"]\""),
                                               "use-fire-prob-se" = "false"
                                             ))


#
# Run 10 times 
#
nl@simdesign <- simdesign_distinct(nl=nl,
                               nseeds=10)

# run in Paralell 
#
#
# Total number of jobs = nseeds * split = 10*4 
# Each job runs parameter input matrix / split = nrow(nl@simdesign@siminput) / split =  300 / 4 
#
plan(multisession)
tic()
results <- run_nl_all(nl,split = 4)
toc()
plan(sequential)
names(results)

#
# Write the output 
#
setsim(nl, "simoutput") <- results 
write_simoutput(nl)

```

# Calculate patch distributions from best fitted parameteres forced with RCP 4.5

* Simulations/Amazon59years449PostRcp45_distinct.csv
* Simulations/Amazon59years449PostRcp45_60_distinct.csv

```{r calcPatchDistSimRCP45_amazon59, echo=FALSE,message=FALSE,warning=FALSE,fig.align='center',eval=FALSE}


# Read previous simulations for RCP 4.5 and fitted parameters
#
list.files(outpath,"Amazon59years449PostRcp45.*\\.csv")

sim <- read_netlogo_simul(file.path(outpath,"Amazon59years449PostRcp45_distinct.csv"),skip=0)
sim <- bind_rows(sim,read_netlogo_simul(file.path(outpath,"Amazon59years449PostRcp45_60_distinct.csv"),skip=0))

# Calculate power law exponents and max/total patch size by year 
#
pexp <- tibble()

plan(multisession)
p_df <- future_lapply( 1:nrow(sim) , function(i){
  df <- netlogo_evaluate_patch_distr(sim$burned_clusters_365[i]) %>%
    mutate(world_width=sim$world_width[i], forest_dispersal_distance=sim$forest_dispersal_distance[i],Forest_growth=sim$Forest_growth[i],Date=sim$Date[i],random_seed=sim$random_seed[i],
           Percent_forest=sim$Percent_forest[i], median_fire_interval= sim$median_fire_interval[i]) %>%
    dplyr::select(world_width,forest_dispersal_distance,Forest_growth,Date,random_seed, everything())
})
pexp <- bind_rows(p_df)
plan(sequential)

saveRDS(pexp, file.path("Simulations", "simExponentsAmazonRCP45_59post.rds"))
```


## 100 Simulations with best parameters and patch size distribution RCP 8.5 (2021 - 2059)

* wordl_width = 450 
* RCP 8.5


```{r sim_simple449clusterRCP85_59post60, echo=FALSE, tidy=TRUE, message=FALSE, warning=FALSE, eval=FALSE}

best <- readRDS(file.path("Simulations","bestFittedExponentsAmazon21yearsPost.rds"))

disp_best <- best %>% dplyr::select(forest_dispersal_distance) %>% deframe()
grow_best <- best %>% ungroup() %>% dplyr::select(Forest_growth) %>% deframe()
ini_best  <- best %>% ungroup() %>% dplyr::select(Initial_forest_density) %>% deframe()
disp_best <- disp_best[41:100]
grow_best <- grow_best[41:100]
ini_best <- ini_best[41:100]

#  from 2001 to 2060
# 
eval_times <- as.numeric(lapply(0:58, function(x){ymd("2001-12-31") + years(x) - ymd("1980-11-01") }))
ymd("1980-11-01") + days(eval_times)


nl@experiment <- experiment(expname="Amazon59years449PostRcp85_60",
                            outpath=outpath,
                            repetition=1,
                            tickmetrics="true",
                            idsetup="setup",
                            idgo="go",
                            #idrunnum="nlrx-experiment",
                            runtime=0,
                            evalticks= eval_times,          # ymd("2011-12-31")  - ymd("1980-11-01") + 1
                            metrics=c("Date", "burned-by-month","active-burned","Percent-forest","fire-probability","burned-clusters 365","median-fire-interval" ),
                            variables = list("forest-dispersal-distance" = list(values=disp_best),
                                             "Forest-growth" = list(values=grow_best),
                                             "Initial-forest-density" = list(values=ini_best)
                                            ),
                            constants = list("world-width" = 449,
                                             "world-height" = 449,
                                               "fire-prob-filename"="\"Data/Predicted_bF_rcp85.csv\"",
                                               "Save-view" =  "false",
                                               "video" = "false",
                                               "end-simulation"= 28918,
                                               "Periodicity" = "false",
                                               "Fire-probability" = 1E-6,
                                               "eval-burned-clusters"=paste0("\"[",paste(eval_times,collapse=" "),"]\""),
                                               "use-fire-prob-se" = "false"
                                             ))


#
# Run 10 times this do not set the run variable for output 
#
nl@simdesign <- simdesign_distinct(nl=nl,
                               nseeds=10)

# run in Paralell 
#
# Total number of jobs = nseeds * split = 10*4 
# Each job runs parameter input matrix / split
nrow(nl@simdesign@siminput) / 4 

plan(multisession)
tic()
results <- run_nl_all(nl,4)
toc()
plan(sequential)
names(results)

#
# Write the output 
#
setsim(nl, "simoutput") <- results 
write_simoutput(nl)

```



# Calculate patch distributions from best fitted parameteres forced with RCP 8.5

```{r calcPatchDistSimRCP85post, echo=FALSE,message=FALSE,warning=FALSE,fig.align='center',eval=TRUE}


# Read previous simulations for RCP 8.5 and fitted parameters
#
list.files(outpath,"Amazon59years449PostRcp85.*\\.csv")

sim <- read_netlogo_simul(file.path(outpath,"Amazon59years449PostRcp85_distinct.csv"),skip=0)
sim <- bind_rows(sim,read_netlogo_simul(file.path(outpath,"Amazon59years449PostRcp85_60_distinct.csv"),skip=0))

# Calculate power law exponents and max/total patch size by year 
#
pexp <- tibble()

plan(multisession)
p_df <- future_lapply( 1:nrow(sim) , function(i){
  df <- netlogo_evaluate_patch_distr(sim$burned_clusters_365[i]) %>%
    mutate(world_width=sim$world_width[i], forest_dispersal_distance=sim$forest_dispersal_distance[i],Forest_growth=sim$Forest_growth[i],Date=sim$Date[i],random_seed=sim$random_seed[i],
           Percent_forest=sim$Percent_forest[i], median_fire_interval= sim$median_fire_interval[i]) %>%
    dplyr::select(world_width,forest_dispersal_distance,Forest_growth,Date,random_seed, everything())
})
pexp <- bind_rows(p_df)
plan(sequential)

saveRDS(pexp, file.path("Simulations", "simExponentsAmazonRCP85_59post.rds"))
```

# Compare with data with simulations period 2000-2020

```{r readCompareSimEstimated_bF, echo=FALSE,message=FALSE,warning=FALSE,fig.align='center',eval=FALSE}

#
# Read experimental data
#

patch_size_pfname <- paste0("Data/patch_sizes_p_BurnedArea_", region_name, ".rds" )
patch_sizes_p <- readRDS(patch_size_pfname)
patch_sizes_p <- patch_sizes_p %>% group_by(date) %>% summarise(max_patch=max(size)/total_forest,tot_patch=sum(size)/total_forest,num_patch=n()/total_forest) %>% mutate(decade="Data", type = "pl",year = date)

# Check with patch_size_p_BurnedArea_ and patch_size_BurnedArea_Amazon have the same values (needs mdat file loaded line 388)
patch_sizes_p %>% inner_join(mdat %>% mutate(year=year(Date)) %>% group_by(year) %>% summarise(tot_patch=sum(total_patch)), by=c("year" = "year")) %>% mutate(tot_patch.x=tot_patch.x*100)

patch_dfp_fname <- paste0("Data/patch_dfp_BurnedArea_", region_name, ".rds" )
patch_dfp <- readRDS(patch_dfp_fname) %>%  group_by(date) %>% filter(AICc == min(AICc))%>% filter(type=="pl") %>% mutate(decade="Data")
patch_dfp %>% ungroup() %>% summarise(across(expo,list(median=median,mean=mean)))

#
# Read simulations based on fitted bF 
#

pexp <- readRDS(file.path("Simulations", "simExponentsAmazonPostfittedBF.rds")) %>% mutate(decade="Simul GAM",tot_patch= tot_patch/(450*450),max_patch=max_patch/(450*450),num_patch=num_patch/(450*450), year= year(Date))

# pexp0 <- readRDS(file.path("Simulations", "simExponentsAmazonfittedBFtheta110.rds")) %>%   filter(world_width==449) %>% mutate(decade="Simul GAM 110",tot_patch= tot_patch/(450*450),max_patch=max_patch/(450*450),num_patch=num_patch/(450*450), year= year(Date))

#
# Read simulations based on actual data
#
pexp1 <- readRDS(file.path("Simulations", "simExponentsAmazonPostTheta61.rds")) %>%
   mutate(decade="Simul Data",tot_patch= tot_patch/(450*450),max_patch=max_patch/(450*450), num_patch=num_patch/(450*450), year= year(Date))

# Add Values of ABC Rejection to check
#
if(FALSE){ 
    best <- readRDS(file.path("Simulations","best_Amazon20yearsTot_lhs.rds"))
    msim <- readRDS(file.path("Simulations","Amazon20yearsTot_lhs.rds"))
    plt <- msim %>% inner_join(best  %>% filter(method=="rejection") %>% distinct() )%>% inner_join(mdat, by=c("Date" = "Date") ) %>%  mutate(year=year(Date)) %>% group_by(Initial_forest_density,forest_dispersal_distance,Forest_growth,year,random_seed) %>%  summarise(tot_patch=sum(burned_by_month)/100, sum_patch=sum(total_patch) ) %>% mutate(decade="Rejection",type="pl")
    
} else {
  plt <- tibble()
}
pexp <- pexp %>% bind_rows(plt,pexp1,patch_sizes_p) %>% mutate(tot_patch= 100 * tot_patch, max_patch= max_patch*100, num_patch=100* num_patch)  ## Make %

pexp %>% count(decade)
require(latex2exp)

#
# Violin Plots
#
require(viridis)
cols =viridis_pal()(3)

p1 <- pexp %>% group_by(random_seed,Date) %>% filter( type == "pl", decade %in% c("Data","Simul Data","Simul GAM"),year>2000) %>% ggplot(aes(decade,max_patch,fill=decade)) + geom_violin() + scale_fill_manual(guide=FALSE,values=cols) +    scale_color_viridis_d() +  ylab("Max Fire Size %") + xlab("")  +  stat_summary(fun.y=median, geom="point", size=2) + scale_x_discrete(labels=c("Data", "Simul Data","Simul GAM"))
#   scale_x_discrete(labels=c("Data", TeX("Simul Data $\\theta=110$"),TeX("Simul Data $\\theta=90$"), TeX("Simul GAM $\\theta=110$"),TeX"Simul GAM $\\theta=90$")))
p1 
#ggsave("figure/Amazon_Max_Size_ModelVsData.png",width=8,height=6,units="in",dpi=600)

p2 <- pexp %>% group_by(random_seed,Date) %>% filter( type == "pl",year>2000) %>% ggplot(aes(decade,tot_patch,fill=decade)) + geom_violin() + scale_fill_manual(guide=FALSE,values=cols) + scale_color_viridis_d() + xlab("") + ylab("Total Fire Size %")  +  stat_summary(fun.y=median, geom="point", size=2) +
  scale_x_discrete(labels=c("Data", "Simul Data","Simul GAM","rejection"))

p2
#ggsave("figure/Amazon_Tot_Size_ModelVsData.png",width=8,height=6,units="in",dpi=600)

p3 <- pexp %>% group_by(random_seed,Date) %>% filter( type == "pl",decade %in% c("Data","Simul Data","Simul GAM"),year>2000) %>% ggplot(aes(decade,num_patch,fill=decade)) + geom_violin() + scale_fill_manual(guide=FALSE,values=cols) + scale_color_viridis_d() + xlab("") + ylab("Number of Fires %")  +  stat_summary(fun.y=median, geom="point", size=2) +
   scale_x_discrete(labels=c("Data", "Simul Data","Simul GAM"))

#   scale_x_discrete(labels=c("Data", "Simul Data", TeX("Simul GAM $\\theta=90$"),TeX("Simul GAM $\\theta=110$")))

p3
#ggsave("figure/Amazon_Num_Fires_ModelVsData.png",width=8,height=6,units="in",dpi=600)

p4 <- pexp %>% group_by(decade,random_seed,Date) %>% filter( type == "pl",decade %in% c("Data","Simul Data","Simul GAM"),year>2000) %>% bind_rows(patch_dfp) %>% mutate(decade=fct_relevel(decade,c("Data","Simul Data 90","Simul GAM 90"))) %>%  ggplot( aes(decade,expo,fill=decade)) + geom_violin() + scale_fill_manual(values=cols,guide=FALSE) +   ylab("Power Law Exponent")  +  stat_summary(fun.y=median, geom="point", size=2) + xlab("") +
   scale_x_discrete(labels=c("Data", "Simul Data","Simul GAM"))

p4
#ggsave("figure/Amazon_PatchExponent_ModelVsData.png",width=8,height=6,units="in",dpi=600)

require(cowplot)
prow <- plot_grid(
  p2+ theme(axis.text.x=element_blank(),axis.title.x=element_blank()),
  p1 + theme(axis.text.x=element_blank(),axis.title.x=element_blank()) , 
  p3 ,
  p4 ,
  align = 'vh',
  nrow= 2
  )
prow

save_plot("figure/Amazon_ModelVsData_SimulGAM.png",prow,base_width=8,base_height=6,dpi=600)

#
# Jitter plots ----> You have an idea of the number of points we are using
#
p1 <- pexp %>% group_by(random_seed,Date) %>% filter( type == "pl", decade %in% c("Data","Simul Data","Simul GAM"),year>2000) %>% ggplot(aes(decade,max_patch,color=decade)) + geom_jitter(alpha=0.5) + scale_fill_viridis_d(guide="none") +    scale_color_viridis_d(guide="none") +  ylab("Max Fire Size %") + xlab("")  +  stat_summary(fun.y=median, geom="point", size=2,color="black") +
  scale_x_discrete(labels=c("Data", "Simul Data","Simul GAM"))
#   scale_x_discrete(labels=c("Data", TeX("Simul Data $\\theta=110$"),TeX("Simul Data $\\theta=90$"), TeX("Simul GAM $\\theta=110$"),TeX("Simul GAM $\\theta=90$")))
p1

# p1 <- pexp %>% group_by(random_seed,Date) %>% filter( type == "pl",year>2000 ) %>% ggplot(aes(decade,tot_patch,color=decade)) + geom_jitter(alpha=0.5) + scale_fill_viridis_d(guide="none") +    scale_color_viridis_d() +  ylab("Max Fire Size %") + xlab("") 
# p1

p2 <- pexp %>% group_by(random_seed,Date) %>% filter( type == "pl", decade %in% c("Data","Simul Data","Simul GAM"),year>2000) %>% ggplot(aes(decade,tot_patch,color=decade)) + geom_jitter(alpha=0.5) + scale_fill_viridis_d(guide="none") +    scale_color_viridis_d(guide="none") + xlab("") + ylab("Total Fire Size %")  +  stat_summary(fun.y=median, geom="point", size=2,color="black") +
  scale_x_discrete(labels=c("Data", "Simul Data","Simul GAM"))

p2

p3 <- pexp %>% group_by(random_seed,Date) %>% filter( type == "pl",decade %in% c("Data","Simul Data","Simul GAM"),year>2000) %>% ggplot(aes(decade,num_patch,color=decade)) + geom_jitter(alpha=0.5) + scale_fill_viridis_d(guide="none") +    scale_color_viridis_d(guide="none") + xlab("") + ylab("Number of Fires %")  +  stat_summary(fun.y=median, geom="point", size=2,color="black") +
   scale_x_discrete(labels=c("Data", "Simul Data","Simul GAM"))
#   scale_x_discrete(labels=c("Data", "Simul Data", TeX("Simul GAM $\\theta=90$"),TeX("Simul GAM $\\theta=110$")))

p3

#cols =viridis_pal()(3)

p4 <- pexp %>% group_by(decade,random_seed,Date) %>% filter( type == "pl",decade %in% c("Data","Simul Data","Simul GAM"),year>2000) %>% bind_rows(patch_dfp) %>% mutate(decade=fct_relevel(decade,c("Data","Simul Data","Simul GAM"))) %>%  ggplot( aes(decade,expo,color=decade)) + geom_jitter(alpha=0.5) + scale_color_manual(values=cols,guide="none") +   ylab("Power Law Exponent")  +  stat_summary(fun.y=median, geom="point", size=2,color="black") + xlab("") +
   scale_x_discrete(labels=c("Data", "Simul Data","Simul GAM"))

p4

require(cowplot)
prow <- plot_grid(
  p2+ theme(axis.text.x=element_blank(),axis.title.x=element_blank()),
  p1 + theme(axis.text.x=element_blank(),axis.title.x=element_blank()) , 
  p3 ,
  p4 ,
  align = 'vh',
  nrow= 2
  )
prow

save_plot("figure/Amazon_ModelVsData_SimulGAM_jitter.png",prow,base_width=8,base_height=6,dpi=600)


#
# Model Forest percent
#
pexp %>% group_by(random_seed,Date) %>% filter( type == "pl",decade!="Data", year>2000) %>%  
      ggplot(aes(Date,Percent_forest,color=decade)) + geom_jitter(alpha=0.3) + scale_color_viridis_d(name="") +  ylab("Forest %") + xlab("") +
      theme(legend.position = c(0.8, 0.88)) 

ggsave("figure/Amazon_ForestPercent_SimulDataGam.png",width=8,height=6,units="in",dpi=600)


#
# Plot in time 
#
pexp0 <- pexp %>% group_by(decade,year) %>% filter( type == "pl", year>2000, decade %in% c("Data","Simul Data", "Simul GAM")) %>%  mutate(decade=factor(decade,levels=c("Data","Simul Data", "Simul GAM"),labels=c("Data","Simul Data", "Simul GAM")))

p1<- pexp0 %>% #group_by(decade,year) %>% filter( type == "pl", year>2000, decade %in% c("Data","Simul Data 90", "Simul GAM 90")) %>% 
  summarise(up_b=quantile(tot_patch,0.975),lo_b=quantile(tot_patch,0.025),tot_patch=median(tot_patch) ) %>%
      ggplot(aes(year,tot_patch,color=decade,fill=decade)) + geom_line(size=1) + 
      scale_color_viridis_d(name="") +  scale_fill_viridis_d(name="") + 
      xlab("Year") + ylab("Total Fire size%") +
      theme(legend.position = c(0.5, 0.5),legend.title = element_text(size=1),legend.text = element_text(size=12)) + geom_ribbon(aes(ymin=lo_b,ymax=up_b),alpha=0.2,linetype=0) 
p1
#ggsave("figure/Amazon_TotalFire_year_SimulDataGam.png",width=8,height=6,units="in",dpi=600)


p2 <- pexp0 %>%  summarise(up_b=quantile(max_patch,0.975),lo_b=quantile(max_patch,0.025),max_patch=median(max_patch) ) %>%
      ggplot(aes(year,max_patch,color=decade,fill=decade)) + geom_line(size=1) + scale_color_viridis_d(name="")+
      scale_fill_viridis_d(name="") + xlab("Year") + ylab("Max Fire size%") +
      theme(legend.position = c(0.8, 0.88)) + geom_ribbon(aes(ymin=lo_b,ymax=up_b),alpha=0.2,linetype=0)
p2
#ggsave("figure/Amazon_MaxFire_year_SimulDataGam.png",width=8,height=6,units="in",dpi=600)


p3 <- pexp0 %>%  summarise(up_b=quantile(num_patch,0.975),lo_b=quantile(num_patch,0.025),num_patch=median(num_patch) ) %>%
      ggplot(aes(year,num_patch,color=decade,fill=decade)) + geom_line(size=1) + scale_color_viridis_d(name="")+
      scale_fill_viridis_d(name="") + xlab("Year") + ylab("Number of Fires%") +
      theme(legend.position = c(0.8, 0.88)) + geom_ribbon(aes(ymin=lo_b,ymax=up_b),alpha=0.2,linetype=0)
p3
# ggsave("figure/Amazon_NumFire_year_SimulDataGam.png",width=8,height=6,units="in",dpi=600)
p4 <- get_legend(p1)
prow <- plot_grid(
  p1 + theme(axis.text.x=element_blank(),axis.title.x=element_blank(),legend.position="none"),
  p2 + theme(axis.title.x=element_blank(),legend.position="none") , 
  p3  + theme(legend.position="none"),
  p4,
  align = 'vh',
  axis= 'lb',
  nrow= 2
  )

prow
save_plot("figure/Amazon_ModelVsData_SimulGAM_year.png",prow,base_width=8,base_height=6,dpi=600,bg = "white")


pexp %>% group_by(decade,year) %>% filter( type == "pl", year>2000) %>%  summarise(num_patch=median(num_patch))%>%
      ggplot(aes(year,num_patch,color=decade)) + geom_line(alpha=0.8) + scale_color_viridis_d(name="") +       xlab("Year") + ylab("Max Fire size%") +
      theme(legend.position = c(0.8, 0.88)) 

```


## Simulations with best parameters and patch size distribution RCP 4.5 (2021 - 2059) Theta 110

* wordl_width = 450 
* RCP 4.5
*  31.23|       5739.33

```{r sim_simple449clusterRCP45theta110_59y, echo=FALSE, tidy=TRUE, message=FALSE, warning=FALSE, eval=FALSE}

#  from 2001 to 2060
# 
eval_times <- as.numeric(lapply(0:58, function(x){ymd("2001-12-31") + years(x) - ymd("1980-11-01") }))
ymd("1980-11-01") + days(eval_times)

# eval_times <- as.numeric(lapply(0:39, function(x){ymd("2020-12-31") + years(x) - ymd("1980-11-01") }))
# ymd("1980-11-01") + days(eval_times)

nl@experiment <- experiment(expname="Amazon39years449rcp45theta110_59y",
                            outpath=outpath,
                            repetition=1,
                            tickmetrics="true",
                            idsetup="setup",
                            idgo="go",
                            #idrunnum="nlrx-experiment",
                            runtime=0,
                            evalticks= eval_times,          # ymd("2011-12-31")  - ymd("1980-11-01") + 1
                            metrics=c("Date", "burned-by-month","active-burned","Percent-forest","fire-probability","burned-clusters 365","median-fire-interval" ),
                            # variables = list("forest-dispersal-distance" = list(values=c(1.61,1.97,1.74)),
                            #                  "Forest-growth" = list(values=c(1419,1778,1361))),
                            constants = list("world-width" = 449,
                                             "world-height" = 449,
                                               "fire-prob-filename"="\"Data/Predicted_bF_rcp45.csv\"",
                                               "Save-view" =  "false",
                                               "video" = "false",
                                               "end-simulation"= 14641,
                                               "Initial-forest-density" = 0.3,
                                               "Periodicity" = "false",
                                               "Fire-probability" = 1E-6,
                                               "forest-dispersal-distance" = 31.23,
                                               "Forest-growth" = 5739.33,
                                               "eval-burned-clusters"=paste0("\"[",paste(eval_times,collapse=" "),"]\""),
                                               "use-fire-prob-se" = "true"
                                             ))


#
# Run 10 times this do not set the run variable for output 
#
nl@simdesign <- simdesign_simple(nl=nl,
                               nseeds=100)
# 
# nl@simdesign <- simdesign_distinct(nl=nl,
#                                nseeds=50)

# run in Paralell 
#
plan(multisession)
tic()
results <- run_nl_all(nl)
#results <- run_nl_all(nl,split = 4)
toc()
plan(sequential)
names(results)

#
# Write the output 
#
setsim(nl, "simoutput") <- results 
write_simoutput(nl)

```



# Plots for the paper!

## Compare with data using total burned area by year and max by year RCP 4.5 and 8.5 theta 90- 110

```{r readCompareSimRCP45-85theta90-110, echo=FALSE,message=FALSE,warning=FALSE,fig.align='center',eval=FALSE}

#
# Read experimental data
#

patch_size_pfname <- paste0("Data/patch_sizes_p_BurnedArea_", region_name, ".rds" )
patch_sizes_p <- readRDS(patch_size_pfname)
patch_sizes_p <- patch_sizes_p %>% group_by(date) %>% summarise(max_patch=max(size)/total_forest,tot_patch=sum(size)/total_forest,num_patch=n()/total_forest) %>% mutate(decade="Data", type = "pl",year = date)


#
# Read simulations based on GAM
#
# pexp <- readRDS(file.path("Simulations", "simExponentsAmazonfittedBF.rds")) %>%   filter(world_width==449) %>% mutate(decade="2001-2021",tot_patch= tot_patch/(450*450),max_patch=max_patch/(450*450),num_patch=num_patch/(450*450), year= year(Date),theta=61,RCP="4.5")


#
# Read Simulations based on RCP 8.5
# 
pexp <- readRDS(file.path("Simulations", "simExponentsAmazonRCP85_59post.rds")) %>% filter(world_width==449) %>% 
                    mutate(tot_patch= tot_patch/(450*450),max_patch=max_patch/(450*450),,num_patch=num_patch/(450*450),
                    year=year(Date),decade=trunc((year - 2000 )/10)*10+2000,decade=paste0(decade , "-", decade+9),decade=factor(decade),theta=61,RCP="8.5")

pexp %>% count(decade,theta)
#
# Read Simulations based on RCP 4.5
#
pexp1 <- readRDS(file.path("Simulations", "simExponentsAmazonRCP45_59post.rds")) %>% filter(world_width==449) %>% 
                     mutate(tot_patch= tot_patch/(450*450),max_patch=max_patch/(450*450),,num_patch=num_patch/(450*450),
                    year=year(Date),decade=trunc((year - 2000 )/10)*10+2000,decade=paste0(decade , "-", decade+9),decade=factor(decade),theta=61,RCP="4.5")

pexp1 %>% count(decade,theta)

pexp <- bind_rows(pexp,pexp1)

pexp %>% count(decade,theta,RCP)

# Add Data
#
pexp <- pexp %>% bind_rows(patch_sizes_p %>% mutate(theta=61,RCP="4.5")) %>%  mutate(tot_patch= 100 * tot_patch, max_patch= max_patch*100, num_patch=100* num_patch) %>% filter(year>2000)## Make %
pexp %>% count(decade,theta)

#
# Model Forest percent
#
pexp %>% mutate(theta=factor(theta)) %>% group_by(RCP,theta,Date) %>% filter( type == "pl",decade!="Data") %>%  summarise(up_b=quantile(Percent_forest,0.975),lo_b=quantile(Percent_forest,0.025),Percent_forest=median(Percent_forest) ) %>%

      ggplot(aes(Date,Percent_forest,color=theta)) + geom_line(size=1) + scale_color_viridis_d(guide="none") +  ylab("Forest %") + xlab("") + geom_ribbon(aes(ymin=lo_b,ymax=up_b),alpha=0.2,linetype=0) +
      theme(legend.position = c(0.1, 0.88)) + facet_wrap(~RCP)

ggsave("figure/Amazon_ForestPercent_theta61_RCP45-85.png",width=8,height=6,units="in",dpi=600)

#
# Predictions from 2020 
#
pdata <- patch_sizes_p %>% mutate(theta=61,RCP="4.5") %>%  mutate(tot_patch= 100 * tot_patch, max_patch= max_patch*100, num_patch=100* num_patch) %>% filter(year>2000)
pdata <- pdata %>% bind_rows(patch_sizes_p %>% mutate(theta=61,RCP="8.5") %>%  mutate(tot_patch= 100 * tot_patch, max_patch= max_patch*100, num_patch=100* num_patch)) %>% filter(year>2000)

pexp %>% group_by(RCP,theta,year) %>% filter( type == "pl", year>2000,decade!="Data") %>%  summarise(up_b=quantile(tot_patch,0.975),lo_b=quantile(tot_patch,0.025),tot_patch=median(tot_patch) ) %>%
      ggplot(aes(year,tot_patch,color=factor(theta),fill=factor(theta))) + geom_line(size=2) + scale_color_viridis_d(guide="none") + scale_fill_viridis_d(guide="none") +
      xlab("Year") + ylab("Total Fire size%") +
      theme(legend.position = c(0.8, 0.88)) + geom_ribbon(aes(ymin=lo_b,ymax=up_b),alpha=0.2,linetype=0) + facet_wrap(~RCP) + geom_point(data=pdata,color="black")
ggsave("figure/Amazon_TotSize_year_theta61_RCP45-85.png",width=8,height=6,units="in",dpi=600)



p1 <- pexp  %>% group_by(random_seed,Date) %>% filter( type == "pl") %>% mutate(theta=factor(if_else(decade=="Data","Data",as.character(theta))), decade=if_else(decade=="Data", "2001-2020",decade))

p1 %>% ungroup() %>% mutate(decade=factor(decade),decade=fct_relevel(decade,c("Data","2001-2020")), theta=fct_recode(theta, "Model"="61")) %>% ggplot(  aes(max_patch,tot_patch, color=theta ))+ geom_point(alpha=0.5) + theme_bw() +
      scale_color_viridis_d(name="")  + 
      xlab("Max Fire size (%)") +  
      ylab("Total Size (%)") +  
      theme(axis.text.x = element_text(angle = 90, hjust = 1))  + facet_grid( RCP ~ decade) +  theme(legend.justification=c(1,0), legend.position=c(.1,0.03))
ggsave("figure/Amazon_TotSizeVsMax_year_theta61_RCP45-85.png",width=8,height=6,units="in",dpi=600)

#
# Power Law exponent VER ACA
#
pexp %>% group_by(random_seed,Date) %>% filter(AICc == min(AICc), type == "pl") %>% bind_rows(patch_dfp %>% mutate(theta=61,RCP="4.5")) %>% mutate(decade=factor(decade),theta=factor(theta),decade=fct_relevel(decade,c("Data","2000-2020")),theta=fct_recode(theta, "Model"="61")) %>% ggplot( aes(decade,expo,fill=decade)) + geom_violin() + scale_fill_viridis_d(guide=FALSE) +    scale_color_viridis_d() + ylab("Power Law Exponent")  +  stat_summary(fun.y=median, geom="point", size=2) + xlab("") + facet_grid( RCP ~theta,drop=TRUE,scales="free_x")+ theme(axis.text.x = element_text(angle = 50, hjust = 1))
ggsave("figure/Amazon_PatchExponent_theta90-110_RCP4.5-8.5.png",width=8,height=6,units="in",dpi=600)

# 
# Number of Fires 
#
pexp %>% group_by(random_seed,Date) %>% filter( type == "pl") %>% mutate(decade=factor(decade),decade=fct_relevel(decade,c("Data","2001-2020"))) %>% ggplot(aes(decade,num_patch,fill=decade)) + geom_violin() + scale_fill_viridis_d(guide=FALSE) +    scale_color_viridis_d() + ylab("Number of Fires (%)")  +  stat_summary(fun=median, geom="point", size=2) + xlab("") + facet_grid( RCP ~theta,drop=TRUE,scales="free_x")+ theme(axis.text.x = element_text(angle = 50, hjust = 1))
ggsave("figure/Amazon_Num_Fires_theta90-110_RCP4.5-8.5.png",width=8,height=6,units="in",dpi=600)

#
# Total size
#
pexp %>% group_by(random_seed,Date) %>% filter( type == "pl") %>% mutate(decade=factor(decade),decade=fct_relevel(decade,c("Data","2001-2020"))) %>% ggplot(aes(decade,tot_patch,fill=decade)) + geom_violin() + scale_fill_viridis_d(guide=FALSE) +    scale_color_viridis_d() + ylab("Total Fire Size (%)")  +  stat_summary(fun=median, geom="point", size=2) + xlab("") + facet_grid( RCP ~theta,drop=TRUE,scales="free_x")+ theme(axis.text.x = element_text(angle = 50, hjust = 1))
ggsave("figure/Amazon_Tot_Size_theta90-110_RCP4.5-8.5.png",width=8,height=6,units="in",dpi=600)

# Max size
#
pexp %>% group_by(random_seed,Date) %>% filter( type == "pl") %>% mutate(decade=factor(decade),decade=fct_relevel(decade,c("Data","2001-2020"))) %>% ggplot(aes(decade,max_patch,fill=decade)) + geom_violin() + scale_fill_viridis_d(guide=FALSE)  +  ylab("Max Fire Size (%)")  +  stat_summary(fun.y=median, geom="point", size=2) + xlab("") + facet_grid( RCP ~theta,drop=TRUE,scales="free_x") + theme(axis.text.x = element_text(angle = 50, hjust = 1))
ggsave("figure/Amazon_Max_Size_theta90-110_RCP4.5-8.5.png",width=8,height=6,units="in",dpi=600)

```
